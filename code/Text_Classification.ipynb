{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ITvyYx54g5C"
   },
   "source": [
    "## Classification with sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1J4daS74g5D"
   },
   "source": [
    "## loading a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                0\n",
      "title                             0\n",
      "assignee                         15\n",
      "inventor/author                 383\n",
      "priority date                   324\n",
      "filing/creation date              6\n",
      "publication date                  1\n",
      "grant date                    13623\n",
      "result link                       0\n",
      "representative figure link    10002\n",
      "code.1                            0\n",
      "citations                         0\n",
      "abstract                        796\n",
      "class                          3384\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "H04L63    2608\n",
       "G06F21    2434\n",
       "G06F16    1192\n",
       "G06Q30     882\n",
       "G06K9/     806\n",
       "          ... \n",
       "B41M3/       1\n",
       "B64D43       1\n",
       "H01J9/       1\n",
       "B41L21       1\n",
       "H02B13       1\n",
       "Name: class, Length: 906, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ids = pd.read_csv(r\"../patents/gp-query2-plus.csv\",index_col='code',skipinitialspace=True)\n",
    "print(ids.isnull().sum())\n",
    "ids['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                0\n",
      "title                             0\n",
      "assignee                          5\n",
      "inventor/author                 369\n",
      "priority date                   315\n",
      "filing/creation date              1\n",
      "publication date                  0\n",
      "grant date                    13565\n",
      "result link                       0\n",
      "representative figure link     9736\n",
      "code.1                            0\n",
      "citations                         0\n",
      "abstract                          0\n",
      "class                             0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "G06    9582\n",
       "NA     6895\n",
       "H04    5300\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids[ids.abstract.notna()]\n",
    "ids[\"class\"].fillna(value=\"NA\",inplace = True)\n",
    "ids['class'] = ids['class'].astype('str').apply(lambda x: x[:3] if len(x) >= 3 else 'NA')\n",
    "ids[\"class\"] = ids[\"class\"].apply(lambda x: 'NA' if x != 'G06' and x != 'H04' else x)\n",
    "ids['abstract'].str.replace(r'[^\\x00-\\x7F]+', '') #dorp chinese character\n",
    "\n",
    "print(ids.isnull().sum())\n",
    "ids['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this if you want to try a binary classification\n",
    "ids = ids[ids['class']!='NA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = ids['abstract'].values\n",
    "y = ids['class'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "70X8gxqX4g5T"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15243, 15243, 6534, 6534)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train),len(y_train),len(x_test),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "62X87ZY84g5Z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'G06', 'H04', 'NA'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8c26tzsE4g5p"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VWoWZd_7uIe"
   },
   "source": [
    "## Tokenization\n",
    "\n",
    "Try the following two cells removing the min_df parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Vk5Cvvyc4g5r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "transform\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5)  # tokenization and frequency count\n",
    "\n",
    "print('fit')\n",
    "vect.fit(x_train)\n",
    "print('transform')\n",
    "X_train_tok = vect.transform(x_train)\n",
    "print('done')\n",
    "\n",
    "# the two steps above can be condensed in a single step that processes train\n",
    "# data only once.\n",
    "\n",
    "# print('fit_transform')\n",
    "# X_train_tok = vect.fit_transform(x_train)\n",
    "# print('done')\n",
    "\n",
    "X_test_tok =vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "D1x3p0T271jX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10022"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PxwBNFrT8UQ0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 8139,\n",
       " 'disclosed': 2564,\n",
       " 'computer': 1748,\n",
       " 'implemented': 4115,\n",
       " 'method': 5132,\n",
       " 'for': 3534,\n",
       " 'detecting': 2429,\n",
       " 'unauthorized': 8476,\n",
       " 'data': 2199,\n",
       " 'shares': 7346,\n",
       " 'may': 5053,\n",
       " 'include': 4157,\n",
       " 'providing': 6398,\n",
       " 'user': 8604,\n",
       " 'of': 5536,\n",
       " 'an': 523,\n",
       " 'anonymized': 586,\n",
       " 'inbox': 4146,\n",
       " 'with': 8963,\n",
       " 'email': 2905,\n",
       " 'to': 8236,\n",
       " 'use': 8597,\n",
       " 'particular': 5782,\n",
       " 'online': 5571,\n",
       " 'entity': 3043,\n",
       " 'identifying': 4058,\n",
       " 'one': 5567,\n",
       " 'or': 5628,\n",
       " 'more': 5263,\n",
       " 'emails': 2906,\n",
       " 'sent': 7291,\n",
       " 'from': 3611,\n",
       " 'different': 2487,\n",
       " 'entities': 3041,\n",
       " 'that': 8138,\n",
       " 'are': 680,\n",
       " 'determining': 2441,\n",
       " 'based': 956,\n",
       " 'on': 5564,\n",
       " 'having': 3888,\n",
       " 'been': 990,\n",
       " 'by': 1254,\n",
       " 'has': 3881,\n",
       " 'shared': 7345,\n",
       " 'other': 5663,\n",
       " 'and': 551,\n",
       " 'creating': 2090,\n",
       " 'privacy': 6253,\n",
       " 'score': 7175,\n",
       " 'at': 774,\n",
       " 'least': 4745,\n",
       " 'in': 4139,\n",
       " 'part': 5769,\n",
       " 'determination': 2435,\n",
       " 'various': 8658,\n",
       " 'methods': 5135,\n",
       " 'systems': 7996,\n",
       " 'readable': 6567,\n",
       " 'media': 5073,\n",
       " 'also': 492,\n",
       " 'present': 6191,\n",
       " 'invention': 4500,\n",
       " 'relates': 6750,\n",
       " 'system': 7992,\n",
       " 'methodology': 5134,\n",
       " 'facilitating': 3322,\n",
       " 'automation': 879,\n",
       " 'security': 7232,\n",
       " 'networked': 5392,\n",
       " 'industrial': 4223,\n",
       " 'controller': 1955,\n",
       " 'environment': 3056,\n",
       " 'components': 1715,\n",
       " 'methodologies': 5133,\n",
       " 'provided': 6394,\n",
       " 'facilitate': 3319,\n",
       " 'varying': 8660,\n",
       " 'levels': 4779,\n",
       " 'accordance': 251,\n",
       " 'analysis': 532,\n",
       " 'tools': 8250,\n",
       " 'validation': 8630,\n",
       " 'learning': 4741,\n",
       " 'tool': 8249,\n",
       " 'receives': 6606,\n",
       " 'abstract': 208,\n",
       " 'factory': 3332,\n",
       " 'models': 5225,\n",
       " 'descriptions': 2385,\n",
       " 'input': 4301,\n",
       " 'generates': 3692,\n",
       " 'output': 5684,\n",
       " 'can': 1300,\n",
       " 'guidelines': 3828,\n",
       " 'topologies': 8258,\n",
       " 'procedures': 6275,\n",
       " 'rules': 7064,\n",
       " 'policies': 6043,\n",
       " 'like': 4808,\n",
       " 'deployment': 2361,\n",
       " 'network': 5391,\n",
       " 'operative': 5597,\n",
       " 'wherein': 8920,\n",
       " 'perform': 5874,\n",
       " 'checking': 1451,\n",
       " 'auditing': 827,\n",
       " 'functions': 3628,\n",
       " 'example': 3159,\n",
       " 'determine': 2438,\n",
       " 'if': 4065,\n",
       " 'place': 5984,\n",
       " 'suitable': 7875,\n",
       " 'working': 8984,\n",
       " 'order': 5631,\n",
       " 'monitors': 5257,\n",
       " 'learns': 4742,\n",
       " 'traffic': 8299,\n",
       " 'patterns': 5826,\n",
       " 'during': 2775,\n",
       " 'phase': 5928,\n",
       " 'fires': 3452,\n",
       " 'alarms': 450,\n",
       " 'events': 3140,\n",
       " 'upon': 8576,\n",
       " 'detected': 2428,\n",
       " 'deviations': 2455,\n",
       " 'learned': 4738,\n",
       " 'causes': 1378,\n",
       " 'automated': 875,\n",
       " 'actions': 292,\n",
       " 'occur': 5526,\n",
       " 'purpose': 6454,\n",
       " 'mobile': 5215,\n",
       " 'terminal': 8105,\n",
       " 'thereof': 8161,\n",
       " 'protect': 6376,\n",
       " 'collect': 1598,\n",
       " 'internal': 4443,\n",
       " 'deleting': 2313,\n",
       " 'stored': 7737,\n",
       " 'tracking': 8288,\n",
       " 'location': 4866,\n",
       " 'when': 8915,\n",
       " 'is': 4547,\n",
       " 'lost': 4904,\n",
       " 'constitution': 1879,\n",
       " 'wireless': 8955,\n",
       " 'communication': 1654,\n",
       " 'unit': 8518,\n",
       " '110': 12,\n",
       " 'wirelessly': 8956,\n",
       " 'external': 3294,\n",
       " 'device': 2456,\n",
       " '130': 29,\n",
       " 'command': 1630,\n",
       " 'control': 1952,\n",
       " '180': 49,\n",
       " 'first': 3459,\n",
       " 'signal': 7407,\n",
       " 'through': 8199,\n",
       " 'display': 2616,\n",
       " 'activated': 294,\n",
       " 'displays': 2620,\n",
       " 'alternative': 500,\n",
       " 'screen': 7182,\n",
       " 'includes': 4159,\n",
       " 'password': 5807,\n",
       " 'window': 8945,\n",
       " 'reference': 6692,\n",
       " 'numerals': 5474,\n",
       " '111': 13,\n",
       " 'broadcast': 1197,\n",
       " 'receiving': 6607,\n",
       " '112': 14,\n",
       " 'module': 5240,\n",
       " '113': 15,\n",
       " 'internet': 4446,\n",
       " '114': 16,\n",
       " 'local': 4857,\n",
       " 'area': 681,\n",
       " '115': 17,\n",
       " 'information': 4252,\n",
       " '120': 22,\n",
       " '121': 23,\n",
       " 'camera': 1295,\n",
       " '122': 24,\n",
       " 'microphone': 5147,\n",
       " '140': 35,\n",
       " 'sensing': 7284,\n",
       " 'proximity': 6406,\n",
       " 'sensor': 7287,\n",
       " '150': 40,\n",
       " '151': 41,\n",
       " 'sound': 7554,\n",
       " '153': 42,\n",
       " 'alarm': 447,\n",
       " '155': 43,\n",
       " 'projector': 6327,\n",
       " '160': 45,\n",
       " 'memory': 5100,\n",
       " '170': 47,\n",
       " 'interface': 4427,\n",
       " 'multimedia': 5309,\n",
       " '190': 51,\n",
       " 'power': 6125,\n",
       " 'supply': 7916,\n",
       " 'kind': 4635,\n",
       " 'emotional': 2929,\n",
       " 'characteristics': 1428,\n",
       " 'parameter': 5754,\n",
       " 'acquisition': 285,\n",
       " 'treatment': 8387,\n",
       " 'realized': 6584,\n",
       " 'intelligent': 4382,\n",
       " 'including': 4160,\n",
       " 'quarantine': 6488,\n",
       " 'server': 7312,\n",
       " 'health': 3898,\n",
       " 'home': 3974,\n",
       " 'addition': 330,\n",
       " 'further': 3637,\n",
       " 'realizing': 6586,\n",
       " 'collects': 1606,\n",
       " 'carries': 1342,\n",
       " 'out': 5670,\n",
       " 'identities': 4059,\n",
       " 'match': 5032,\n",
       " 'obtains': 5512,\n",
       " 'corresponding': 2035,\n",
       " 'fitness': 3464,\n",
       " 'login': 4882,\n",
       " 'encrypted': 2975,\n",
       " 'encryption': 2977,\n",
       " 'storage': 7735,\n",
       " 'using': 8608,\n",
       " 'solve': 7536,\n",
       " 'region': 6718,\n",
       " 'limitation': 4814,\n",
       " 'traditional': 8298,\n",
       " 'exchange': 3177,\n",
       " 'follow': 3523,\n",
       " 'up': 8561,\n",
       " 'face': 3315,\n",
       " 'medical': 5078,\n",
       " 'worker': 8980,\n",
       " 'increased': 4178,\n",
       " 'substantially': 7839,\n",
       " 'emotion': 2928,\n",
       " 'identification': 4050,\n",
       " 'capacity': 1316,\n",
       " 'auxiliary': 888,\n",
       " 'diagnosis': 2464,\n",
       " 'ensure': 3021,\n",
       " 'patients': 5821,\n",
       " 'wider': 8935,\n",
       " 'range': 6532,\n",
       " 'application': 640,\n",
       " 'discloses': 2565,\n",
       " 'crop': 2111,\n",
       " 'growing': 3810,\n",
       " 'stage': 7658,\n",
       " 'model': 5221,\n",
       " 'parameters': 5756,\n",
       " 'under': 8485,\n",
       " 'condition': 1786,\n",
       " 'uncertainty': 8480,\n",
       " 'automatically': 877,\n",
       " 'correct': 2015,\n",
       " 'frame': 3589,\n",
       " 'some': 7541,\n",
       " 'key': 4624,\n",
       " 'links': 4830,\n",
       " 'similarity': 7427,\n",
       " 'measurements': 5066,\n",
       " 'quantity': 6484,\n",
       " 'algorithm': 457,\n",
       " 'adaptive': 324,\n",
       " 'differential': 2488,\n",
       " 'evolution': 3148,\n",
       " 'coupling': 2062,\n",
       " 'solves': 7539,\n",
       " 'choose': 1467,\n",
       " 'weather': 8881,\n",
       " 'conditions': 1791,\n",
       " 'big': 1067,\n",
       " 'set': 7323,\n",
       " 'many': 4999,\n",
       " 'years': 9014,\n",
       " 'temperature': 8086,\n",
       " 'light': 4804,\n",
       " 'attribute': 809,\n",
       " 'feature': 3377,\n",
       " 'difference': 2485,\n",
       " 'degree': 2304,\n",
       " 'represents': 6850,\n",
       " 'locality': 4858,\n",
       " 'sample': 7117,\n",
       " 'as': 715,\n",
       " 'correction': 2018,\n",
       " 'crucial': 2124,\n",
       " 'period': 5883,\n",
       " 'variable': 8647,\n",
       " 'all': 466,\n",
       " 'filtered': 3427,\n",
       " 'target': 8037,\n",
       " 'function': 3622,\n",
       " 'calculates': 1277,\n",
       " 'its': 4569,\n",
       " 'missing': 5193,\n",
       " 'values': 8638,\n",
       " 'knowledge': 4648,\n",
       " 'measured': 5064,\n",
       " 'self': 7263,\n",
       " 'features': 3379,\n",
       " 'carrys': 1345,\n",
       " 'calibration': 1286,\n",
       " 'finally': 3432,\n",
       " 'estimation': 3120,\n",
       " 'parametric': 5757,\n",
       " 'results': 6939,\n",
       " 'preferably': 6164,\n",
       " 'representative': 6847,\n",
       " 'group': 3804,\n",
       " 'robustness': 7013,\n",
       " 'selected': 7254,\n",
       " 'means': 5061,\n",
       " 'clustering': 1557,\n",
       " 'improved': 4132,\n",
       " 'so': 7512,\n",
       " 'simulation': 7442,\n",
       " 'error': 3092,\n",
       " 'minimum': 5180,\n",
       " 'better': 1048,\n",
       " 'stability': 7648,\n",
       " 'convenient': 1960,\n",
       " 'actual': 306,\n",
       " 'production': 6295,\n",
       " 'embodiments': 2914,\n",
       " 'there': 8153,\n",
       " 'devices': 2457,\n",
       " 'capturing': 1326,\n",
       " 'images': 4091,\n",
       " 'substances': 7837,\n",
       " 'scene': 7155,\n",
       " 'such': 7861,\n",
       " 'illumination': 4081,\n",
       " 'imaging': 4092,\n",
       " 'included': 4158,\n",
       " 'housing': 4011,\n",
       " 'configured': 1814,\n",
       " 'be': 974,\n",
       " 'inserted': 4316,\n",
       " 'toilet': 8239,\n",
       " 'cleaning': 1520,\n",
       " 'receive': 6602,\n",
       " 'comprising': 1738,\n",
       " 'high': 3937,\n",
       " 'quality': 6476,\n",
       " 'capture': 1323,\n",
       " 'image': 4087,\n",
       " 'video': 8723,\n",
       " 'processor': 6283,\n",
       " 'analyzing': 545,\n",
       " 'captured': 1324,\n",
       " 'identify': 4057,\n",
       " 'characteristic': 1427,\n",
       " 'type': 8449,\n",
       " 'stopper': 7732,\n",
       " 'bottles': 1157,\n",
       " 'especially': 3103,\n",
       " 'small': 7494,\n",
       " 'which': 8922,\n",
       " 'essentially': 3107,\n",
       " 'characterized': 1431,\n",
       " 'being': 1007,\n",
       " 'composed': 1717,\n",
       " 'sealing': 7200,\n",
       " 'body': 1129,\n",
       " 'material': 5037,\n",
       " 'shape': 7341,\n",
       " 'dimensions': 2517,\n",
       " 'completed': 1700,\n",
       " 'appropriate': 653,\n",
       " 'stop': 7730,\n",
       " 'drive': 2742,\n",
       " 'head': 3893,\n",
       " 'side': 7397,\n",
       " 'radially': 6510,\n",
       " 'pin': 5971,\n",
       " 'same': 7116,\n",
       " 'extends': 3287,\n",
       " 'parallel': 5752,\n",
       " 'theoretical': 8148,\n",
       " 'axis': 912,\n",
       " 'plug': 6021,\n",
       " 'assembly': 733,\n",
       " 'gripping': 3800,\n",
       " 'retention': 6948,\n",
       " 'elements': 2887,\n",
       " 'determined': 2439,\n",
       " 'teeth': 8071,\n",
       " 'established': 3110,\n",
       " 'said': 7112,\n",
       " 'introduced': 4480,\n",
       " 'hole': 3970,\n",
       " 'made': 4933,\n",
       " 'support': 7918,\n",
       " 'propaganda': 6348,\n",
       " 'bottle': 1155,\n",
       " 'medium': 5083,\n",
       " 'cardboard': 1330,\n",
       " 'bottom': 1158,\n",
       " 'box': 1165,\n",
       " 'container': 1907,\n",
       " 'similar': 7425,\n",
       " 'apply': 644,\n",
       " 'little': 4844,\n",
       " 'closed': 1543,\n",
       " 'acts': 305,\n",
       " 'effective': 2826,\n",
       " 'latter': 4707,\n",
       " 'thanks': 8137,\n",
       " 'hook': 3983,\n",
       " 'action': 290,\n",
       " 'precisely': 6144,\n",
       " 'machine': 4927,\n",
       " 'translation': 8348,\n",
       " 'google': 3748,\n",
       " 'translate': 8344,\n",
       " 'not': 5444,\n",
       " 'legally': 4757,\n",
       " 'binding': 1083,\n",
       " 'provides': 6397,\n",
       " 'robot': 7009,\n",
       " 'operating': 5592,\n",
       " 'efficiency': 2833,\n",
       " 'controlled': 1954,\n",
       " 'possesses': 6103,\n",
       " 'characterised': 1426,\n",
       " 'possess': 6101,\n",
       " 'acceptance': 228,\n",
       " 'division': 2669,\n",
       " 'received': 6603,\n",
       " 'operation': 5593,\n",
       " 'second': 7213,\n",
       " '3rd': 120,\n",
       " 'two': 8448,\n",
       " 'operations': 5596,\n",
       " '4th': 144,\n",
       " '5th': 163,\n",
       " 'carry': 1343,\n",
       " 'coordinate': 1994,\n",
       " 'section': 7220,\n",
       " 'calculate': 1275,\n",
       " 'posture': 6118,\n",
       " 'plane': 5993,\n",
       " 'scope': 7174,\n",
       " 'distance': 2636,\n",
       " 'datum': 2212,\n",
       " 'mark': 5009,\n",
       " 'have': 3887,\n",
       " 'calculating': 1278,\n",
       " 'instrument': 4359,\n",
       " 'apparatus': 626,\n",
       " 'predicting': 6153,\n",
       " 'quantum': 6487,\n",
       " 'state': 7680,\n",
       " 'dynamics': 2782,\n",
       " 'far': 3355,\n",
       " 'it': 4561,\n",
       " 'subjects': 7808,\n",
       " 'community': 1659,\n",
       " 'addressed': 336,\n",
       " 'marketing': 5014,\n",
       " 'representation': 6845,\n",
       " 'adopted': 365,\n",
       " 'herein': 3922,\n",
       " 'states': 7684,\n",
       " 'assigned': 746,\n",
       " 'subject': 7803,\n",
       " 'defined': 2294,\n",
       " 'respect': 6904,\n",
       " 'underlying': 8489,\n",
       " 'proposition': 6370,\n",
       " 'about': 201,\n",
       " 'item': 4562,\n",
       " 'instantiated': 4343,\n",
       " 'object': 5490,\n",
       " 'experience': 3237,\n",
       " 'product': 6294,\n",
       " 'service': 7315,\n",
       " 'identified': 4052,\n",
       " 'basis': 963,\n",
       " 'spectral': 7600,\n",
       " 'decomposition': 2256,\n",
       " 'referred': 6696,\n",
       " 'social': 7514,\n",
       " 'value': 8636,\n",
       " 'context': 1921,\n",
       " 'teaches': 8053,\n",
       " 'populations': 6076,\n",
       " 'amongst': 514,\n",
       " 'who': 8927,\n",
       " 'will': 8942,\n",
       " 'respond': 6908,\n",
       " 'certain': 1402,\n",
       " 'way': 8868,\n",
       " 'interest': 4422,\n",
       " 'this': 8177,\n",
       " 'mechanical': 5069,\n",
       " 'probabilities': 6265,\n",
       " 'vectors': 8667,\n",
       " 'representing': 6849,\n",
       " 'botnets': 1153,\n",
       " 'cloud': 1552,\n",
       " 'computing': 1755,\n",
       " 'infrastructure': 4262,\n",
       " 'gathering': 3674,\n",
       " 'feeds': 3388,\n",
       " 'over': 5693,\n",
       " 'predefined': 6147,\n",
       " 'detection': 2430,\n",
       " 'time': 8220,\n",
       " 'produce': 6289,\n",
       " 'dataset': 2204,\n",
       " 'bot': 1150,\n",
       " 'labels': 4669,\n",
       " 'related': 6749,\n",
       " 'activity': 302,\n",
       " 'each': 2783,\n",
       " 'virtual': 8742,\n",
       " 'generating': 3693,\n",
       " 'vector': 8664,\n",
       " 'plurality': 6025,\n",
       " 'machines': 4930,\n",
       " 'scores': 7177,\n",
       " 'botnet': 1152,\n",
       " 'transmitting': 8359,\n",
       " 'generated': 3691,\n",
       " 'supervised': 7901,\n",
       " 'decision': 2243,\n",
       " 'generate': 3690,\n",
       " 'label': 4666,\n",
       " 'indicating': 4200,\n",
       " 'respective': 6905,\n",
       " 'labeled': 4667,\n",
       " 'hacking': 3842,\n",
       " 'defense': 2288,\n",
       " 'contest': 1920,\n",
       " 'capable': 1314,\n",
       " 'verifying': 8692,\n",
       " 'vulnerability': 8810,\n",
       " 'patch': 5811,\n",
       " 'particularly': 5784,\n",
       " 'analyze': 540,\n",
       " 'attack': 786,\n",
       " 'their': 8142,\n",
       " 'terminals': 8106,\n",
       " 'verified': 8688,\n",
       " 'derive': 2373,\n",
       " 'evaluation': 3131,\n",
       " 'compensating': 1683,\n",
       " 'created': 2088,\n",
       " 'comprise': 1735,\n",
       " 'hardware': 3873,\n",
       " 'programmable': 6310,\n",
       " 'search': 7204,\n",
       " 'content': 1917,\n",
       " 'regular': 6728,\n",
       " 'expression': 3282,\n",
       " 'converted': 1972,\n",
       " 'into': 4475,\n",
       " 'non': 5429,\n",
       " 'deterministic': 2442,\n",
       " 'finite': 3449,\n",
       " 'automata': 873,\n",
       " 'functionality': 3625,\n",
       " 'recognition': 6621,\n",
       " 'processing': 6282,\n",
       " 'contains': 1911,\n",
       " 'amount': 515,\n",
       " 'database': 2200,\n",
       " 'used': 8601,\n",
       " 'communicatively': 1656,\n",
       " 'connected': 1836,\n",
       " 'recognizes': 6626,\n",
       " 'fields': 3409,\n",
       " 'where': 8917,\n",
       " 'money': 5253,\n",
       " 'recorded': 6651,\n",
       " 'compares': 1671,\n",
       " 'field': 3408,\n",
       " 'coloring': 1612,\n",
       " 'instruction': 4356,\n",
       " 'color': 1610,\n",
       " 'patches': 5812,\n",
       " 'according': 252,\n",
       " 'instructions': 4357,\n",
       " 'replace': 6824,\n",
       " 'these': 8167,\n",
       " 'respectively': 6906,\n",
       " 'containing': 1909,\n",
       " 'blocks': 1114,\n",
       " 'dual': 2760,\n",
       " 'synchronize': 7975,\n",
       " 'hot': 4000,\n",
       " 'spare': 7572,\n",
       " 'active': 299,\n",
       " 'synchronizes': 7977,\n",
       " 'applied': 642,\n",
       " 'synchronous': 7979,\n",
       " 'mainly': 4946,\n",
       " 'primary': 6227,\n",
       " 'standby': 7672,\n",
       " 'carried': 1339,\n",
       " 'distributed': 2652,\n",
       " 'mode': 5220,\n",
       " 'consistency': 1861,\n",
       " 'locked': 4871,\n",
       " 'between': 1050,\n",
       " 'cluster': 1555,\n",
       " 'arranged': 692,\n",
       " 'client': 1531,\n",
       " 'read': 6566,\n",
       " 'write': 9002,\n",
       " 'locks': 4873,\n",
       " 'safety': 7111,\n",
       " 'executing': 3195,\n",
       " 'step': 7709,\n",
       " 'guarantee': 3817,\n",
       " 'granularity': 3778,\n",
       " 'only': 5572,\n",
       " 'improve': 4131,\n",
       " 'effeciency': 2822,\n",
       " 'business': 1240,\n",
       " 'importantly': 4122,\n",
       " 'clients': 1532,\n",
       " 'written': 9006,\n",
       " 'lock': 4870,\n",
       " 'exclusive': 3188,\n",
       " 'affairs': 394,\n",
       " 'namely': 5343,\n",
       " 'servers': 7313,\n",
       " 'situation': 7460,\n",
       " 'simultaneously': 7446,\n",
       " 'but': 1244,\n",
       " 'cannot': 1307,\n",
       " 'ensured': 3022,\n",
       " 'enclosure': 2961,\n",
       " 'intrusion': 4487,\n",
       " 'sensors': 7289,\n",
       " 'associated': 759,\n",
       " '105': 7,\n",
       " 'comprises': 1737,\n",
       " 'following': 3525,\n",
       " 'types': 8451,\n",
       " 'ultrasonic': 8464,\n",
       " 'acoustic': 278,\n",
       " 'electromagnetic': 2876,\n",
       " 'transmission': 8352,\n",
       " 'line': 4819,\n",
       " 'movement': 5292,\n",
       " 'human': 4021,\n",
       " 'door': 2698,\n",
       " 'status': 7695,\n",
       " 'furthermore': 3638,\n",
       " 'analyzed': 541,\n",
       " 'event': 3139,\n",
       " 'occurred': 5527,\n",
       " 'alert': 453,\n",
       " 'issued': 4556,\n",
       " 'integrated': 4374,\n",
       " 'log': 4875,\n",
       " 'management': 4973,\n",
       " 'artificial': 712,\n",
       " 'intelligence': 4381,\n",
       " 'occurring': 5530,\n",
       " 'enterprise': 3031,\n",
       " 'build': 1221,\n",
       " 'base': 955,\n",
       " 'kb': 4616,\n",
       " 'attacks': 791,\n",
       " 'malicious': 4964,\n",
       " 'abnormal': 197,\n",
       " 'behavior': 999,\n",
       " 'performing': 5879,\n",
       " 'correlation': 2027,\n",
       " 'entire': 3038,\n",
       " 'built': 1226,\n",
       " 'disclosure': 2567,\n",
       " 'lighting': 4805,\n",
       " 'switch': 7960,\n",
       " 'circuit': 1482,\n",
       " 'cause': 1376,\n",
       " 'transmitter': 8357,\n",
       " 'communicably': 1649,\n",
       " 'coupled': 2060,\n",
       " 'initiate': 4279,\n",
       " 'direct': 2521,\n",
       " 'electronic': 2879,\n",
       " 'via': 8715,\n",
       " 'protocol': 6385,\n",
       " 'remote': 6797,\n",
       " 'factor': 3329,\n",
       " 'authentication': 852,\n",
       " 'serial': 7307,\n",
       " 'number': 5469,\n",
       " 'actuator': 311,\n",
       " 'obtain': 5509,\n",
       " 'wi': 8932,\n",
       " 'fi': 3402,\n",
       " 'credentials': 2095,\n",
       " 'sequence': 7302,\n",
       " 'improving': 4136,\n",
       " 'performance': 5875,\n",
       " 'school': 7166,\n",
       " 'zone': 9028,\n",
       " 'cctv': 1384,\n",
       " 'surveillance': 7938,\n",
       " 'stores': 7739,\n",
       " 'photographed': 5940,\n",
       " 'still': 7718,\n",
       " 'perspective': 5917,\n",
       " 'transmits': 8355,\n",
       " 'omnidirectional': 5563,\n",
       " 'main': 4944,\n",
       " 'center': 1391,\n",
       " 'extracts': 3303,\n",
       " 'faces': 3317,\n",
       " 'people': 5858,\n",
       " 'contours': 1936,\n",
       " 'program': 6309,\n",
       " 'encrypts': 2978,\n",
       " 'coordinates': 1996,\n",
       " 'codes': 1570,\n",
       " 'facial': 3318,\n",
       " 'contour': 1935,\n",
       " 'wanted': 8830,\n",
       " 'criminals': 2104,\n",
       " 'sex': 7335,\n",
       " 'recording': 6653,\n",
       " 'monitor': 5254,\n",
       " 'configure': 1813,\n",
       " 'store': 7736,\n",
       " 'link': 4825,\n",
       " 'trading': 8296,\n",
       " 'prices': 6224,\n",
       " 'drawn': 2736,\n",
       " 'personal': 5909,\n",
       " 'file': 3416,\n",
       " 'combined': 1622,\n",
       " 'resulting': 6938,\n",
       " 'interactions': 4400,\n",
       " 'creation': 2091,\n",
       " 'software': 7524,\n",
       " 'items': 4563,\n",
       " 'owned': 5712,\n",
       " 'combination': 1619,\n",
       " 'sources': 7558,\n",
       " 'form': 3553,\n",
       " 'digital': 2505,\n",
       " 'persona': 5907,\n",
       " 'traded': 8293,\n",
       " 'sold': 7527,\n",
       " 'retained': 6945,\n",
       " 'private': 6254,\n",
       " 'marketplace': 5015,\n",
       " 'provision': 6400,\n",
       " 'healthcare': 3899,\n",
       " 'procedure': 6274,\n",
       " 'agents': 413,\n",
       " 'equipment': 3068,\n",
       " 'quantifying': 6480,\n",
       " 'designation': 2393,\n",
       " 'position': 6092,\n",
       " 'care': 1334,\n",
       " 'providers': 6396,\n",
       " 'relative': 6757,\n",
       " 'communications': 1655,\n",
       " 'multiple': 5312,\n",
       " 'transceivers': 8319,\n",
       " 'ongoing': 5570,\n",
       " 'monitoring': 5256,\n",
       " 'facility': 3325,\n",
       " 'provide': 6393,\n",
       " 'augmented': 835,\n",
       " 'reality': 6581,\n",
       " 'view': 8726,\n",
       " 'positions': 6097,\n",
       " 'skill': 7471,\n",
       " 'objective': 5491,\n",
       " 'wagering': 8814,\n",
       " 'interactive': 4401,\n",
       " 'game': 3653,\n",
       " 'process': 6279,\n",
       " 'player': 6013,\n",
       " 'presentation': 6192,\n",
       " 'detects': 2434,\n",
       " 'outcome': 5672,\n",
       " 'communicates': 1652,\n",
       " 'operatively': 5598,\n",
       " 'constructed': 1885,\n",
       " 'random': 6527,\n",
       " 'result': 6935,\n",
       " 'generator': 3697,\n",
       " 'communicate': 1650,\n",
       " 'processors': 6284,\n",
       " 'priority': 6249,\n",
       " 'packet': 5725,\n",
       " 'assign': 745,\n",
       " 'queue': 6500,\n",
       " 'node': 5424,\n",
       " 'vehicle': 8668,\n",
       " 'transponder': 8363,\n",
       " 'anti': 602,\n",
       " 'collision': 1607,\n",
       " 'id': 4043,\n",
       " 'described': 2381,\n",
       " 'message': 5119,\n",
       " 'free': 3597,\n",
       " 'pre': 6138,\n",
       " 'permanent': 5891,\n",
       " 'hybrid': 4029,\n",
       " 'offset': 5555,\n",
       " 'units': 8521,\n",
       " 'geographical': 3708,\n",
       " 'grid': 3796,\n",
       " 'proxy': 6407,\n",
       " 'equipped': 3070,\n",
       " 'coding': 1571,\n",
       " 'mac': 4926,\n",
       " 'ip': 4539,\n",
       " 'addresses': 337,\n",
       " 'no': 5422,\n",
       " 'central': 1394,\n",
       " 'authority': 863,\n",
       " 'road': 7006,\n",
       " 'required': 6867,\n",
       " 'vehicles': 8669,\n",
       " 'combat': 1618,\n",
       " 'countermeasure': 2051,\n",
       " 'training': 8308,\n",
       " 'subsystem': 7846,\n",
       " 'site': 7455,\n",
       " 'single': 7449,\n",
       " 'soldier': 7528,\n",
       " 'subsystems': 7847,\n",
       " 'observation': 5501,\n",
       " 'targets': 8040,\n",
       " 'exercise': 3199,\n",
       " 'setting': 7326,\n",
       " 'achieved': 270,\n",
       " 'effect': 2823,\n",
       " 'shooting': 7368,\n",
       " 'effectively': 2827,\n",
       " 'released': 6763,\n",
       " 'issuance': 4554,\n",
       " 'optimal': 5613,\n",
       " 'export': 3269,\n",
       " 'development': 2449,\n",
       " 'kit': 4641,\n",
       " 'above': 202,\n",
       " 'mentioned': 5103,\n",
       " 'pass': 5795,\n",
       " 'timeliness': 8222,\n",
       " 'accuracy': 266,\n",
       " 'meet': 5085,\n",
       " 'strategy': 7749,\n",
       " 'web': 8882,\n",
       " 'flat': 3486,\n",
       " 'thin': 8171,\n",
       " 'materials': 5038,\n",
       " 'consists': 1865,\n",
       " 'die': 2481,\n",
       " 'cut': 2162,\n",
       " 'format': 3555,\n",
       " 'major': 4953,\n",
       " 'surface': 7928,\n",
       " 'general': 3686,\n",
       " 'configuration': 1810,\n",
       " 'stretched': 7764,\n",
       " 'projected': 6323,\n",
       " 'backward': 925,\n",
       " 'locking': 4872,\n",
       " 'bound': 1160,\n",
       " 'sizes': 7467,\n",
       " 'presenting': 6195,\n",
       " 'opposite': 5608,\n",
       " 'end': 2979,\n",
       " 'extension': 3289,\n",
       " 'sections': 7222,\n",
       " 'front': 3612,\n",
       " 'visor': 8760,\n",
       " 'lateral': 4703,\n",
       " 'projecting': 6324,\n",
       " '12': 21,\n",
       " '13': 28,\n",
       " 'fitted': 3466,\n",
       " '14': 34,\n",
       " '15': 39,\n",
       " 'overlap': 5700,\n",
       " '10': 0,\n",
       " '11': 11,\n",
       " 'disposed': 2624,\n",
       " 'top': 8253,\n",
       " 'supplements': 7911,\n",
       " '16': 44,\n",
       " '17': 46,\n",
       " 'adjacent': 347,\n",
       " '컴퓨터에': 9888,\n",
       " '의하여': 9657,\n",
       " '수행되는': 9521,\n",
       " '방법에': 9360,\n",
       " '있어서': 9726,\n",
       " '포함된': 9939,\n",
       " '이미지를': 9669,\n",
       " '획득하는': 10015,\n",
       " '단계': 9218,\n",
       " 's110': 7077,\n",
       " '상기': 9435,\n",
       " '하나': 9971,\n",
       " '이상의': 9679,\n",
       " '도출하는': 9260,\n",
       " 's120': 7079,\n",
       " '설정된': 9486,\n",
       " '규칙을': 9164,\n",
       " 's130': 7080,\n",
       " '기반하여': 9180,\n",
       " '대응하는': 9242,\n",
       " '정보를': 9785,\n",
       " 's140': 7081,\n",
       " '포함할': 9947,\n",
       " '있다': 9723,\n",
       " 'performed': 5877,\n",
       " 'obtaining': 5511,\n",
       " 'pattern': 5823,\n",
       " 'deriving': 2376,\n",
       " 'predetermined': 6148,\n",
       " 'rule': 7063,\n",
       " 'relies': 6774,\n",
       " 'embodiment': 2913,\n",
       " 'speech': 7605,\n",
       " 'validate': 8626,\n",
       " 'requires': 6870,\n",
       " 'initially': 4278,\n",
       " 'station': 7687,\n",
       " 'responsive': 6918,\n",
       " 'then': 8147,\n",
       " 'validated': 8627,\n",
       " 'thereafter': 8154,\n",
       " 'randomly': 6530,\n",
       " 'challenge': 1412,\n",
       " 'phrase': 5948,\n",
       " 'appears': 633,\n",
       " 'speak': 7578,\n",
       " 'response': 6914,\n",
       " 'speaks': 7582,\n",
       " 'spoken': 7620,\n",
       " 'processed': 6280,\n",
       " 'what': 8911,\n",
       " 'was': 8845,\n",
       " 'actually': 307,\n",
       " 'well': 8904,\n",
       " 'voice': 8779,\n",
       " 'speaking': 7581,\n",
       " 'complete': 1699,\n",
       " 'access': 232,\n",
       " 'given': 3728,\n",
       " 'changing': 1421,\n",
       " 'manner': 4989,\n",
       " 'reduces': 6685,\n",
       " 'possibility': 6106,\n",
       " 'intruder': 4485,\n",
       " 'true': 8415,\n",
       " '발명은': 9351,\n",
       " '보안': 9380,\n",
       " '연동하는': 9610,\n",
       " '자동': 9729,\n",
       " '시스템에': 9541,\n",
       " '관한': 9149,\n",
       " '것으로': 9109,\n",
       " '하는': 9975,\n",
       " '여러': 9598,\n",
       " '대하여': 9244,\n",
       " '실시간으로': 9560,\n",
       " '종류의': 9826,\n",
       " '자동으로': 9730,\n",
       " '명령을': 9320,\n",
       " '실시간': 9559,\n",
       " '가능하게': 9063,\n",
       " '서로': 9459,\n",
       " '다른': 9212,\n",
       " '각각': 9076,\n",
       " '수신하는': 9508,\n",
       " '탐지': 9898,\n",
       " '수신부': 9506,\n",
       " '수신된': 9505,\n",
       " '분석하고': 9398,\n",
       " '따라': 9292,\n",
       " '해당': 9990,\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ipJykPr14g5u"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '100',\n",
       " '1000',\n",
       " '101',\n",
       " '102',\n",
       " '103',\n",
       " '104',\n",
       " '105',\n",
       " '106',\n",
       " '107',\n",
       " '108',\n",
       " '11',\n",
       " '110',\n",
       " '111',\n",
       " '112',\n",
       " '113',\n",
       " '114',\n",
       " '115',\n",
       " '116',\n",
       " '118',\n",
       " '119',\n",
       " '12',\n",
       " '120',\n",
       " '121',\n",
       " '122',\n",
       " '123',\n",
       " '124',\n",
       " '125',\n",
       " '13',\n",
       " '130',\n",
       " '131',\n",
       " '132',\n",
       " '133',\n",
       " '135',\n",
       " '14',\n",
       " '140',\n",
       " '142',\n",
       " '144',\n",
       " '145',\n",
       " '15',\n",
       " '150',\n",
       " '151',\n",
       " '153',\n",
       " '155',\n",
       " '16',\n",
       " '160',\n",
       " '17',\n",
       " '170',\n",
       " '18',\n",
       " '180',\n",
       " '19',\n",
       " '190',\n",
       " '1a',\n",
       " '1b',\n",
       " '1차',\n",
       " '20',\n",
       " '200',\n",
       " '2004',\n",
       " '2005',\n",
       " '2007',\n",
       " '201',\n",
       " '2011',\n",
       " '202',\n",
       " '2021',\n",
       " '203',\n",
       " '204',\n",
       " '205',\n",
       " '206',\n",
       " '208',\n",
       " '21',\n",
       " '210',\n",
       " '212',\n",
       " '214',\n",
       " '215',\n",
       " '216',\n",
       " '22',\n",
       " '220',\n",
       " '22a',\n",
       " '23',\n",
       " '230',\n",
       " '24',\n",
       " '240',\n",
       " '25',\n",
       " '250',\n",
       " '26',\n",
       " '260',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '2a',\n",
       " '2d',\n",
       " '2nd',\n",
       " '2차',\n",
       " '30',\n",
       " '300',\n",
       " '301',\n",
       " '302',\n",
       " '303',\n",
       " '304',\n",
       " '305',\n",
       " '306',\n",
       " '31',\n",
       " '310',\n",
       " '311',\n",
       " '312',\n",
       " '314',\n",
       " '32',\n",
       " '320',\n",
       " '33',\n",
       " '330',\n",
       " '34',\n",
       " '35',\n",
       " '350',\n",
       " '36',\n",
       " '360',\n",
       " '38',\n",
       " '3a',\n",
       " '3b',\n",
       " '3d',\n",
       " '3g',\n",
       " '3rd',\n",
       " '3차원',\n",
       " '40',\n",
       " '400',\n",
       " '401',\n",
       " '402',\n",
       " '404',\n",
       " '41',\n",
       " '410',\n",
       " '411',\n",
       " '412',\n",
       " '42',\n",
       " '420',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '4d',\n",
       " '4e',\n",
       " '4ea',\n",
       " '4ej',\n",
       " '4g',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '501',\n",
       " '502',\n",
       " '504',\n",
       " '51',\n",
       " '510',\n",
       " '512',\n",
       " '52',\n",
       " '520',\n",
       " '53',\n",
       " '530',\n",
       " '54',\n",
       " '540',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '5g',\n",
       " '5th',\n",
       " '60',\n",
       " '600',\n",
       " '61',\n",
       " '62',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '70',\n",
       " '72',\n",
       " '80',\n",
       " '800',\n",
       " '802',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '90',\n",
       " '92',\n",
       " '95',\n",
       " '98',\n",
       " '99',\n",
       " 'a1',\n",
       " 'a2',\n",
       " 'aa',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abhängigkeit',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abnormal',\n",
       " 'abnormalities',\n",
       " 'abnormality',\n",
       " 'abnormity',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abrasion',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absorption',\n",
       " 'abstract',\n",
       " 'abstracted',\n",
       " 'abstracting',\n",
       " 'abstraction',\n",
       " 'abstractions',\n",
       " 'abundant',\n",
       " 'abuse',\n",
       " 'abusive',\n",
       " 'ac',\n",
       " 'academic',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accelerates',\n",
       " 'accelerating',\n",
       " 'acceleration',\n",
       " 'accelerator',\n",
       " 'accelerometer',\n",
       " 'accept',\n",
       " 'acceptability',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessed',\n",
       " 'accesses',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accessing',\n",
       " 'accessories',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidents',\n",
       " 'accommodate',\n",
       " 'accommodated',\n",
       " 'accommodating',\n",
       " 'accommodation',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accord',\n",
       " 'accordance',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accords',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulates',\n",
       " 'accumulating',\n",
       " 'accumulation',\n",
       " 'accumulator',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'acid',\n",
       " 'acids',\n",
       " 'acknowledgement',\n",
       " 'acknowledgment',\n",
       " 'acoustic',\n",
       " 'acoustically',\n",
       " 'acousto',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquires',\n",
       " 'acquiring',\n",
       " 'acquisition',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actionable',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'activates',\n",
       " 'activating',\n",
       " 'activation',\n",
       " 'activations',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'actuated',\n",
       " 'actuating',\n",
       " 'actuation',\n",
       " 'actuator',\n",
       " 'acurrate',\n",
       " 'acyclic',\n",
       " 'ad',\n",
       " 'adaboost',\n",
       " 'adapt',\n",
       " 'adaptability',\n",
       " 'adaptable',\n",
       " 'adaptation',\n",
       " 'adapted',\n",
       " 'adapter',\n",
       " 'adapting',\n",
       " 'adaption',\n",
       " 'adaptive',\n",
       " 'adaptively',\n",
       " 'adapts',\n",
       " 'add',\n",
       " 'added',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additive',\n",
       " 'address',\n",
       " 'addressable',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adhered',\n",
       " 'adhering',\n",
       " 'adhesion',\n",
       " 'adhesive',\n",
       " 'adjacency',\n",
       " 'adjacent',\n",
       " 'adjust',\n",
       " 'adjustable',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'adjusts',\n",
       " 'administer',\n",
       " 'administered',\n",
       " 'administering',\n",
       " 'administration',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'administrators',\n",
       " 'admins',\n",
       " 'admission',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'adopts',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantageous',\n",
       " 'advantageously',\n",
       " 'advantages',\n",
       " 'adversarial',\n",
       " 'adverse',\n",
       " 'adversely',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertisements',\n",
       " 'advertiser',\n",
       " 'advertisers',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'aerial',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affects',\n",
       " 'affiliated',\n",
       " 'affinity',\n",
       " 'affixed',\n",
       " 'afforded',\n",
       " 'aforementioned',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'aggregate',\n",
       " 'aggregated',\n",
       " 'aggregates',\n",
       " 'aggregating',\n",
       " 'aggregation',\n",
       " 'aggregator',\n",
       " 'agile',\n",
       " 'aging',\n",
       " 'agnostic',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'agreements',\n",
       " 'agricultural',\n",
       " 'ahead',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aided',\n",
       " 'aids',\n",
       " 'aiheuttamalla',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aims',\n",
       " 'air',\n",
       " 'airborne',\n",
       " 'aircraft',\n",
       " 'airplane',\n",
       " 'airplanes',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'ais',\n",
       " 'al',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alarming',\n",
       " 'alarms',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'alert',\n",
       " 'alerted',\n",
       " 'alerting',\n",
       " 'alerts',\n",
       " 'algorithm',\n",
       " 'algorithmic',\n",
       " 'algorithmically',\n",
       " 'algorithms',\n",
       " 'alia',\n",
       " 'align',\n",
       " 'aligned',\n",
       " 'aligning',\n",
       " 'alignment',\n",
       " 'all',\n",
       " 'allegedly',\n",
       " 'alleviate',\n",
       " 'alleviates',\n",
       " 'alleviation',\n",
       " 'alliance',\n",
       " 'allocate',\n",
       " 'allocated',\n",
       " 'allocates',\n",
       " 'allocating',\n",
       " 'allocation',\n",
       " 'allow',\n",
       " 'allowable',\n",
       " 'allowance',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alloy',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alpha',\n",
       " 'alphabet',\n",
       " 'alphanumeric',\n",
       " 'already',\n",
       " 'als',\n",
       " 'also',\n",
       " 'alter',\n",
       " 'alteration',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternate',\n",
       " 'alternately',\n",
       " 'alternating',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'alternatives',\n",
       " 'although',\n",
       " 'altitude',\n",
       " 'always',\n",
       " 'am',\n",
       " 'ambient',\n",
       " 'ambiguities',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'amendment',\n",
       " 'amino',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'amounts',\n",
       " 'amplification',\n",
       " 'amplified',\n",
       " 'amplifier',\n",
       " 'amplifying',\n",
       " 'amplitude',\n",
       " 'amusement',\n",
       " 'an',\n",
       " 'analog',\n",
       " 'analogous',\n",
       " 'analogue',\n",
       " 'analyse',\n",
       " 'analysed',\n",
       " 'analyser',\n",
       " 'analyses',\n",
       " 'analysing',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'analysts',\n",
       " 'analyte',\n",
       " 'analytes',\n",
       " 'analytic',\n",
       " 'analytical',\n",
       " 'analytics',\n",
       " 'analyze',\n",
       " 'analyzed',\n",
       " 'analyzer',\n",
       " 'analyzers',\n",
       " 'analyzes',\n",
       " 'analyzing',\n",
       " 'anatomical',\n",
       " 'anatomy',\n",
       " 'anchor',\n",
       " 'anchoring',\n",
       " 'ancillary',\n",
       " 'and',\n",
       " 'andere',\n",
       " 'anderen',\n",
       " 'android',\n",
       " 'anesthetic',\n",
       " 'anesthetics',\n",
       " 'angeordnet',\n",
       " 'angeordneten',\n",
       " 'angle',\n",
       " 'angles',\n",
       " 'angular',\n",
       " 'anhand',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'ann',\n",
       " 'annotate',\n",
       " 'annotated',\n",
       " 'annotating',\n",
       " 'annotation',\n",
       " 'annotations',\n",
       " 'announce',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'announcements',\n",
       " 'announcing',\n",
       " 'annual',\n",
       " 'annular',\n",
       " 'anode',\n",
       " 'anomalies',\n",
       " 'anomalous',\n",
       " 'anomaly',\n",
       " 'anonymity',\n",
       " 'anonymization',\n",
       " 'anonymized',\n",
       " 'anonymizing',\n",
       " 'anonymous',\n",
       " 'anonymously',\n",
       " 'anordnung',\n",
       " 'another',\n",
       " 'ansiosta',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'antagonistic',\n",
       " 'antenna',\n",
       " 'antennas',\n",
       " 'anterior',\n",
       " 'anthrax',\n",
       " 'anti',\n",
       " 'antibodies',\n",
       " 'antibody',\n",
       " 'anticipated',\n",
       " 'anticipating',\n",
       " 'antigen',\n",
       " 'antivirus',\n",
       " 'antriebseinheit',\n",
       " 'antwort',\n",
       " 'anweisungen',\n",
       " 'anwendung',\n",
       " 'anxiety',\n",
       " 'any',\n",
       " 'anyone',\n",
       " 'anytime',\n",
       " 'anywhere',\n",
       " 'anzahl',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'aperture',\n",
       " 'api',\n",
       " 'apis',\n",
       " 'apk',\n",
       " 'app',\n",
       " 'apparatus',\n",
       " 'apparatuses',\n",
       " 'apparent',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'appended',\n",
       " 'applet',\n",
       " 'appliance',\n",
       " 'appliances',\n",
       " 'applicability',\n",
       " 'applicable',\n",
       " 'application',\n",
       " 'applications',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appointed',\n",
       " 'appointment',\n",
       " 'appraisal',\n",
       " 'appreciated',\n",
       " 'approach',\n",
       " 'approaches',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'appropriateness',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'approving',\n",
       " 'approximate',\n",
       " 'approximated',\n",
       " 'approximately',\n",
       " 'approximation',\n",
       " 'apps',\n",
       " 'apron',\n",
       " 'apt',\n",
       " 'ar',\n",
       " 'arbitrarily',\n",
       " 'arbitrary',\n",
       " 'arbitration',\n",
       " 'arc',\n",
       " 'architectural',\n",
       " 'architecture',\n",
       " 'architectures',\n",
       " 'archival',\n",
       " 'archive',\n",
       " 'archived',\n",
       " 'archives',\n",
       " 'archiving',\n",
       " 'are',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'arise',\n",
       " 'arising',\n",
       " 'arithmetic',\n",
       " 'arm',\n",
       " 'arms',\n",
       " 'around',\n",
       " 'arrange',\n",
       " 'arranged',\n",
       " 'arrangement',\n",
       " 'arrangements',\n",
       " 'arranges',\n",
       " 'arranging',\n",
       " 'array',\n",
       " 'arrays',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrow',\n",
       " 'art',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'articulamentum',\n",
       " 'articulated',\n",
       " 'artifact',\n",
       " 'artifacts',\n",
       " 'artificial',\n",
       " 'artificially',\n",
       " 'artistic',\n",
       " 'as',\n",
       " 'ascending',\n",
       " 'ascertain',\n",
       " 'ascertained',\n",
       " 'ascertaining',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asm',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'assay',\n",
       " 'assays',\n",
       " 'assemble',\n",
       " 'assembled',\n",
       " 'assemblies',\n",
       " 'assembling',\n",
       " 'assembly',\n",
       " 'asserted',\n",
       " 'assertion',\n",
       " 'assertions',\n",
       " 'assess',\n",
       " 'assessed',\n",
       " 'assesses',\n",
       " 'assessing',\n",
       " 'assessment',\n",
       " 'assessments',\n",
       " 'asset',\n",
       " 'assets',\n",
       " 'assign',\n",
       " 'assigned',\n",
       " 'assigning',\n",
       " 'assignment',\n",
       " 'assignments',\n",
       " 'assigns',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'assistants',\n",
       " 'assisted',\n",
       " 'assisting',\n",
       " 'assists',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'associates',\n",
       " 'associating',\n",
       " 'association',\n",
       " 'associations',\n",
       " 'associative',\n",
       " 'assumed',\n",
       " 'assuming',\n",
       " 'assurance',\n",
       " 'assure',\n",
       " 'assuring',\n",
       " 'asteen',\n",
       " 'asthma',\n",
       " 'asymmetric',\n",
       " 'asynchronous',\n",
       " 'at',\n",
       " 'atm',\n",
       " 'atmosphere',\n",
       " 'atmospheric',\n",
       " 'atom',\n",
       " 'atomic',\n",
       " 'attach',\n",
       " 'attachable',\n",
       " 'attached',\n",
       " 'attaching',\n",
       " 'attachment',\n",
       " 'attachments',\n",
       " 'attack',\n",
       " 'attacked',\n",
       " 'attacker',\n",
       " 'attackers',\n",
       " 'attacking',\n",
       " 'attacks',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attempts',\n",
       " 'attendance',\n",
       " 'attended',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attenuation',\n",
       " 'attestation',\n",
       " 'attitude',\n",
       " 'attract',\n",
       " 'attracted',\n",
       " 'attracting',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'attributable',\n",
       " 'attribute',\n",
       " 'attributed',\n",
       " 'attributes',\n",
       " 'attributing',\n",
       " 'attribution',\n",
       " 'atypical',\n",
       " 'au',\n",
       " 'auch',\n",
       " 'auction',\n",
       " 'auctions',\n",
       " 'audible',\n",
       " 'audience',\n",
       " 'audiences',\n",
       " 'audient',\n",
       " 'audio',\n",
       " 'audiovisual',\n",
       " 'audit',\n",
       " 'audited',\n",
       " 'auditing',\n",
       " 'auditory',\n",
       " 'auf',\n",
       " 'aufweisen',\n",
       " 'aufweisend',\n",
       " 'aufweist',\n",
       " 'augment',\n",
       " 'augmentation',\n",
       " 'augmented',\n",
       " 'augmenting',\n",
       " 'aural',\n",
       " 'aus',\n",
       " 'ausführen',\n",
       " 'ausführung',\n",
       " 'ausführungsformen',\n",
       " 'ausgebildet',\n",
       " 'ausgeführt',\n",
       " 'ausgewählt',\n",
       " 'ausgewählten',\n",
       " 'auszuführen',\n",
       " 'authentic',\n",
       " 'authenticate',\n",
       " 'authenticated',\n",
       " 'authenticates',\n",
       " 'authenticating',\n",
       " 'authentication',\n",
       " 'authenticator',\n",
       " 'authenticity',\n",
       " 'authentification',\n",
       " 'author',\n",
       " 'authored',\n",
       " 'authoring',\n",
       " 'authorisation',\n",
       " 'authorised',\n",
       " 'authoritative',\n",
       " 'authorities',\n",
       " 'authority',\n",
       " 'authorization',\n",
       " 'authorize',\n",
       " 'authorized',\n",
       " 'authorizes',\n",
       " 'authorizing',\n",
       " 'authors',\n",
       " 'auto',\n",
       " 'autocorrelation',\n",
       " 'autoencoder',\n",
       " 'automata',\n",
       " 'automate',\n",
       " 'automated',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'automating',\n",
       " 'automation',\n",
       " 'automatisch',\n",
       " 'automaton',\n",
       " 'automobile',\n",
       " 'automotive',\n",
       " 'autonomic',\n",
       " 'autonomous',\n",
       " 'autonomously',\n",
       " 'autonomy',\n",
       " 'auxiliary',\n",
       " 'av',\n",
       " 'availability',\n",
       " 'available',\n",
       " 'avatar',\n",
       " 'avatars',\n",
       " 'average',\n",
       " 'averaged',\n",
       " 'averaging',\n",
       " 'aviation',\n",
       " 'avoid',\n",
       " 'avoidance',\n",
       " 'avoided',\n",
       " 'avoiding',\n",
       " 'avoids',\n",
       " 'awaiting',\n",
       " 'award',\n",
       " 'awarding',\n",
       " 'awards',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'away',\n",
       " 'axes',\n",
       " 'axial',\n",
       " 'axis',\n",
       " 'axle',\n",
       " 'azimuth',\n",
       " 'back',\n",
       " 'backbone',\n",
       " 'backed',\n",
       " 'backend',\n",
       " 'background',\n",
       " 'backing',\n",
       " 'backstage',\n",
       " 'backtracking',\n",
       " 'backup',\n",
       " 'backups',\n",
       " 'backward',\n",
       " 'bacteria',\n",
       " 'bacterial',\n",
       " 'bacterium',\n",
       " 'bad',\n",
       " 'baffle',\n",
       " 'bag',\n",
       " 'bagging',\n",
       " 'bags',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'balances',\n",
       " 'balancing',\n",
       " 'ball',\n",
       " 'balloon',\n",
       " 'ballot',\n",
       " 'ballots',\n",
       " 'band',\n",
       " 'bands',\n",
       " 'bandwidth',\n",
       " 'bank',\n",
       " 'banking',\n",
       " 'banks',\n",
       " 'banner',\n",
       " 'bar',\n",
       " 'barcode',\n",
       " 'barrel',\n",
       " 'barrier',\n",
       " 'barriers',\n",
       " 'bars',\n",
       " 'base',\n",
       " 'based',\n",
       " 'baseline',\n",
       " 'baselines',\n",
       " 'bases',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basierend',\n",
       " 'basis',\n",
       " 'basket',\n",
       " 'batch',\n",
       " 'batches',\n",
       " 'batteries',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'bayes',\n",
       " 'bayesian',\n",
       " 'bayonet',\n",
       " 'bb',\n",
       " 'be',\n",
       " 'beacon',\n",
       " 'beacons',\n",
       " 'bead',\n",
       " 'beam',\n",
       " 'beams',\n",
       " 'bean',\n",
       " 'bear',\n",
       " 'bearing',\n",
       " 'bears',\n",
       " 'beautiful',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begins',\n",
       " 'behalf',\n",
       " 'behaves',\n",
       " 'behaving',\n",
       " 'behavior',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "X2lgD7Y04g5x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x10022 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 60 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tok[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2mik5K904g51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 492)\t1\n",
      "  (0, 523)\t2\n",
      "  (0, 551)\t2\n",
      "  (0, 586)\t1\n",
      "  (0, 680)\t2\n",
      "  (0, 774)\t1\n",
      "  (0, 956)\t2\n",
      "  (0, 990)\t1\n",
      "  (0, 1254)\t1\n",
      "  (0, 1748)\t2\n",
      "  (0, 2090)\t1\n",
      "  (0, 2199)\t1\n",
      "  (0, 2429)\t1\n",
      "  (0, 2435)\t1\n",
      "  (0, 2441)\t1\n",
      "  (0, 2487)\t3\n",
      "  (0, 2564)\t2\n",
      "  (0, 2905)\t4\n",
      "  (0, 2906)\t2\n",
      "  (0, 3041)\t4\n",
      "  (0, 3043)\t5\n",
      "  (0, 3534)\t3\n",
      "  (0, 3611)\t2\n",
      "  (0, 3881)\t2\n",
      "  (0, 3888)\t1\n",
      "  :\t:\n",
      "  (0, 5263)\t3\n",
      "  (0, 5536)\t1\n",
      "  (0, 5564)\t2\n",
      "  (0, 5567)\t3\n",
      "  (0, 5571)\t5\n",
      "  (0, 5628)\t3\n",
      "  (0, 5663)\t3\n",
      "  (0, 5769)\t1\n",
      "  (0, 5782)\t5\n",
      "  (0, 6253)\t1\n",
      "  (0, 6398)\t1\n",
      "  (0, 6567)\t1\n",
      "  (0, 7175)\t1\n",
      "  (0, 7291)\t2\n",
      "  (0, 7345)\t2\n",
      "  (0, 7346)\t1\n",
      "  (0, 7996)\t1\n",
      "  (0, 8138)\t3\n",
      "  (0, 8139)\t11\n",
      "  (0, 8236)\t2\n",
      "  (0, 8476)\t1\n",
      "  (0, 8597)\t1\n",
      "  (0, 8604)\t3\n",
      "  (0, 8658)\t1\n",
      "  (0, 8963)\t3\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tok[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nopxC-YP4g54"
   },
   "source": [
    "Some scikit-learn modules implement an inverse_transform method to reconstruct input from their output.\n",
    "Let's print out the feature names and their frequency for a document. Note that frequency info is lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zjh8ymz_4g55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['also', 'an', 'and', 'anonymized', 'are', 'at', 'based', 'been',\n",
       "        'by', 'computer', 'creating', 'data', 'detecting', 'determination',\n",
       "        'determining', 'different', 'disclosed', 'email', 'emails',\n",
       "        'entities', 'entity', 'for', 'from', 'has', 'having',\n",
       "        'identifying', 'implemented', 'in', 'inbox', 'include', 'least',\n",
       "        'may', 'media', 'method', 'methods', 'more', 'of', 'on', 'one',\n",
       "        'online', 'or', 'other', 'part', 'particular', 'privacy',\n",
       "        'providing', 'readable', 'score', 'sent', 'shared', 'shares',\n",
       "        'systems', 'that', 'the', 'to', 'unauthorized', 'use', 'user',\n",
       "        'various', 'with'], dtype='<U23')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.inverse_transform(X_train_tok[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FziDW-YRBGRP"
   },
   "source": [
    "Let's attach frequency data to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_gU1QgQx88iR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "also 1\n",
      "an 2\n",
      "and 2\n",
      "anonymized 1\n",
      "are 2\n",
      "at 1\n",
      "based 2\n",
      "been 1\n",
      "by 1\n",
      "computer 2\n",
      "creating 1\n",
      "data 1\n",
      "detecting 1\n",
      "determination 1\n",
      "determining 1\n",
      "different 3\n",
      "disclosed 2\n",
      "email 4\n",
      "emails 2\n",
      "entities 4\n",
      "entity 5\n",
      "for 3\n",
      "from 2\n",
      "has 2\n",
      "having 1\n",
      "identifying 1\n",
      "implemented 1\n",
      "in 1\n",
      "inbox 1\n",
      "include 1\n",
      "least 1\n",
      "may 1\n",
      "media 1\n",
      "method 1\n",
      "methods 1\n",
      "more 3\n",
      "of 1\n",
      "on 2\n",
      "one 3\n",
      "online 5\n",
      "or 3\n",
      "other 3\n",
      "part 1\n",
      "particular 5\n",
      "privacy 1\n",
      "providing 1\n",
      "readable 1\n",
      "score 1\n",
      "sent 2\n",
      "shared 2\n",
      "shares 1\n",
      "systems 1\n",
      "that 3\n",
      "the 11\n",
      "to 2\n",
      "unauthorized 1\n",
      "use 1\n",
      "user 3\n",
      "various 1\n",
      "with 3\n"
     ]
    }
   ],
   "source": [
    "for feat,freq in zip(vect.inverse_transform(X_train_tok[0,:])[0],X_train_tok[0,:].data):\n",
    "  print(feat,freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHFnwDZO7Ucs"
   },
   "source": [
    "## Feature selection\n",
    "\n",
    "This is the first element where we use the labels, because it is a supervised method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KCHhR_bExfa"
   },
   "source": [
    "# Multi-class single-label classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUl_XQlGE53g"
   },
   "source": [
    "Tokenization does not change from the binary problem, as the dataset is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-vKvHMkE073"
   },
   "source": [
    "## Feature selection\n",
    "\n",
    "Here we use single-label labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DYXqOJy7E075"
   },
   "outputs": [],
   "source": [
    "sel = SelectKBest(chi2, k=5000)  # feature selection\n",
    "sel.fit(X_train_tok,y_train)\n",
    "X_train_sel = sel.transform(X_train_tok)\n",
    "X_test_sel = sel.transform(X_test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9uZCJLrGE08G"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, ..., False, False,  True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gLT0SCitE08L"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14590x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 736531 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "DyK7_GdjE08W"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 57 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sel[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MJIlACkxE08b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 132)\t2\n",
      "  (0, 147)\t1\n",
      "  (0, 230)\t2\n",
      "  (0, 250)\t1\n",
      "  (0, 264)\t3\n",
      "  (0, 313)\t1\n",
      "  (0, 358)\t1\n",
      "  (0, 422)\t3\n",
      "  (0, 424)\t1\n",
      "  (0, 438)\t1\n",
      "  (0, 480)\t2\n",
      "  (0, 488)\t1\n",
      "  (0, 905)\t1\n",
      "  (0, 907)\t1\n",
      "  (0, 934)\t2\n",
      "  (0, 990)\t1\n",
      "  (0, 1135)\t3\n",
      "  (0, 1240)\t1\n",
      "  (0, 1289)\t1\n",
      "  (0, 1497)\t1\n",
      "  (0, 1559)\t1\n",
      "  (0, 1621)\t1\n",
      "  (0, 1814)\t1\n",
      "  (0, 1956)\t1\n",
      "  (0, 2003)\t1\n",
      "  :\t:\n",
      "  (0, 2662)\t1\n",
      "  (0, 2685)\t1\n",
      "  (0, 2812)\t2\n",
      "  (0, 2841)\t3\n",
      "  (0, 2864)\t1\n",
      "  (0, 3166)\t2\n",
      "  (0, 3168)\t1\n",
      "  (0, 3246)\t1\n",
      "  (0, 3415)\t1\n",
      "  (0, 3473)\t1\n",
      "  (0, 3497)\t1\n",
      "  (0, 3703)\t2\n",
      "  (0, 3734)\t1\n",
      "  (0, 3759)\t1\n",
      "  (0, 3763)\t1\n",
      "  (0, 4133)\t6\n",
      "  (0, 4134)\t1\n",
      "  (0, 4213)\t10\n",
      "  (0, 4250)\t1\n",
      "  (0, 4454)\t7\n",
      "  (0, 4456)\t1\n",
      "  (0, 4527)\t1\n",
      "  (0, 4621)\t1\n",
      "  (0, 4636)\t1\n",
      "  (0, 4650)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X_train_sel[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1qbRIgeE08g"
   },
   "source": [
    "Selected feature differ from the binary case, as now they have to be informative with respect to a different set of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "EVbxoMzcE08l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['activities', 'additional', 'also', 'an', 'and', 'appearance',\n",
      "       'as', 'authentication', 'authenticity', 'average', 'based', 'be',\n",
      "       'compute', 'computer', 'confidence', 'context', 'data',\n",
      "       'determine', 'disclosed', 'engine', 'example', 'face', 'gait',\n",
      "       'heuristic', 'how', 'in', 'include', 'is', 'made', 'may', 'method',\n",
      "       'monitoring', 'more', 'movements', 'on', 'or', 'other',\n",
      "       'predictive', 'preemptively', 'programmed', 'receives',\n",
      "       'regarding', 'relevant', 'score', 'security', 'sensitive',\n",
      "       'sensors', 'system', 'systems', 'the', 'thus', 'user', 'users',\n",
      "       'vision', 'when', 'will', 'with'], dtype='<U23')]\n"
     ]
    }
   ],
   "source": [
    "print(vect.inverse_transform(sel.inverse_transform(X_train_sel[0,:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqtNzTeME08o"
   },
   "source": [
    "## Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "kddCsL0dE08o"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()  # weighting\n",
    "tfidf.fit(X_train_sel)\n",
    "X_train_vec = tfidf.transform(X_train_sel)\n",
    "X_test_vec =tfidf.transform(X_test_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "iTQeGJJrE08q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4650)\t0.034272298568714096\n",
      "  (0, 4636)\t0.09441563442789391\n",
      "  (0, 4621)\t0.06222415493203917\n",
      "  (0, 4527)\t0.12091226230577407\n",
      "  (0, 4456)\t0.08109826660544252\n",
      "  (0, 4454)\t0.34343175641297063\n",
      "  (0, 4250)\t0.10444083330306983\n",
      "  (0, 4213)\t0.2098293130559417\n",
      "  (0, 4134)\t0.0583023914838006\n",
      "  (0, 4133)\t0.22569164369898215\n",
      "  (0, 3763)\t0.10112786007181591\n",
      "  (0, 3759)\t0.1133982148558292\n",
      "  (0, 3734)\t0.06417650906055922\n",
      "  (0, 3703)\t0.1845377564700082\n",
      "  (0, 3497)\t0.09815259091710517\n",
      "  (0, 3473)\t0.10838838490452433\n",
      "  (0, 3415)\t0.08428770084936733\n",
      "  (0, 3246)\t0.12556817813384408\n",
      "  (0, 3168)\t0.17856473617256763\n",
      "  (0, 3166)\t0.25444401455767124\n",
      "  (0, 2864)\t0.06025679643819927\n",
      "  (0, 2841)\t0.11318451484390893\n",
      "  (0, 2812)\t0.06373517689641844\n",
      "  (0, 2685)\t0.1471623486233739\n",
      "  (0, 2662)\t0.05262046952507982\n",
      "  :\t:\n",
      "  (0, 2003)\t0.11968098028110531\n",
      "  (0, 1956)\t0.15067277433141268\n",
      "  (0, 1814)\t0.16922589454070208\n",
      "  (0, 1621)\t0.09870197780775031\n",
      "  (0, 1559)\t0.08125720457436793\n",
      "  (0, 1497)\t0.09539358743868143\n",
      "  (0, 1289)\t0.06312193144805782\n",
      "  (0, 1240)\t0.06982790469292266\n",
      "  (0, 1135)\t0.11785880028143918\n",
      "  (0, 990)\t0.10371859858230141\n",
      "  (0, 934)\t0.23514491103999968\n",
      "  (0, 907)\t0.056214065394377684\n",
      "  (0, 905)\t0.13635108229602771\n",
      "  (0, 488)\t0.03976257020505832\n",
      "  (0, 480)\t0.07871228227827023\n",
      "  (0, 438)\t0.13252031165829034\n",
      "  (0, 424)\t0.13069602445925688\n",
      "  (0, 422)\t0.2627578572936257\n",
      "  (0, 358)\t0.04547826034956724\n",
      "  (0, 313)\t0.13128640273970454\n",
      "  (0, 264)\t0.06410727234926107\n",
      "  (0, 250)\t0.03194567743810638\n",
      "  (0, 230)\t0.12022588922074352\n",
      "  (0, 147)\t0.09958671748470396\n",
      "  (0, 132)\t0.22807590244780057\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vec[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "U-7IAy_2E08s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activities 0.034272298568714096\n",
      "additional 0.09441563442789391\n",
      "also 0.06222415493203917\n",
      "an 0.12091226230577407\n",
      "and 0.08109826660544252\n",
      "appearance 0.34343175641297063\n",
      "as 0.10444083330306983\n",
      "authentication 0.2098293130559417\n",
      "authenticity 0.0583023914838006\n",
      "average 0.22569164369898215\n",
      "based 0.10112786007181591\n",
      "be 0.1133982148558292\n",
      "compute 0.06417650906055922\n",
      "computer 0.1845377564700082\n",
      "confidence 0.09815259091710517\n",
      "context 0.10838838490452433\n",
      "data 0.08428770084936733\n",
      "determine 0.12556817813384408\n",
      "disclosed 0.17856473617256763\n",
      "engine 0.25444401455767124\n",
      "example 0.06025679643819927\n",
      "face 0.11318451484390893\n",
      "gait 0.06373517689641844\n",
      "heuristic 0.1471623486233739\n",
      "how 0.05262046952507982\n",
      "in 0.07234580545317308\n",
      "include 0.03557971313596843\n",
      "is 0.22413141851956067\n",
      "made 0.09217845430916606\n",
      "may 0.08278330533398488\n",
      "method 0.061691253819134\n",
      "monitoring 0.026788405829879864\n",
      "more 0.11968098028110531\n",
      "movements 0.15067277433141268\n",
      "on 0.16922589454070208\n",
      "or 0.09870197780775031\n",
      "other 0.08125720457436793\n",
      "predictive 0.09539358743868143\n",
      "preemptively 0.06312193144805782\n",
      "programmed 0.06982790469292266\n",
      "receives 0.11785880028143918\n",
      "regarding 0.10371859858230141\n",
      "relevant 0.23514491103999968\n",
      "score 0.056214065394377684\n",
      "security 0.13635108229602771\n",
      "sensitive 0.03976257020505832\n",
      "sensors 0.07871228227827023\n",
      "system 0.13252031165829034\n",
      "systems 0.13069602445925688\n",
      "the 0.2627578572936257\n",
      "thus 0.04547826034956724\n",
      "user 0.13128640273970454\n",
      "users 0.06410727234926107\n",
      "vision 0.03194567743810638\n",
      "when 0.12022588922074352\n",
      "will 0.09958671748470396\n",
      "with 0.22807590244780057\n"
     ]
    }
   ],
   "source": [
    "for feat,weight in zip(vect.inverse_transform(sel.inverse_transform(X_train_vec[0,:]))[0],X_train_vec[0,:].data):\n",
    "  print(feat,weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUEjfuYlE08u"
   },
   "source": [
    "## Learning algorithm\n",
    "\n",
    "Linear SVM implement multi-class single-label using a one-vs-rest approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "gyIr1ypPE08u"
   },
   "outputs": [],
   "source": [
    "learner = LinearSVC()  # linear svm with default parameters\n",
    "classifier = learner.fit(X_train_vec,y_train)\n",
    "predictions = classifier.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "H_zL5N2-E08w"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7187"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "TqnqooVyE080"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['H04', 'NA', 'G06', ..., 'NA', 'NA', 'NA'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfxllwx8E083"
   },
   "source": [
    "## Evaluation of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "FAJWosMxE084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6847085014609712\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for prediction,true_label in zip(predictions, y_test):\n",
    "    if prediction==true_label:\n",
    "        correct += 1\n",
    "print(correct/len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ay23cQTUE087"
   },
   "source": [
    "## Using sklearn pipeline object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3y7s_LKE087"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),  # feature extraction\n",
    "    ('sel', SelectKBest(chi2, k=3000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', MLPClassifier())  # learning algorithm\n",
    "])\n",
    "\n",
    "classifier = pipeline.fit(x_train,y_train)\n",
    "predictions = classifier.predict(x_test)\n",
    "correct = 0\n",
    "for prediction,true_label in zip(predictions, y_test):\n",
    "    if prediction==true_label:\n",
    "        correct += 1\n",
    "print(correct/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-rQMii8E089"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hD-76IqUZ7Vp"
   },
   "source": [
    "The classification score for the binary classifier we learned earlier is different, though it is trained on exactly the same data. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkxDjHG-aSyo"
   },
   "source": [
    "We try a linear svm with one-vs-one model.\n",
    "\n",
    "LinearSVC does not implement OvO.\n",
    "\n",
    "We can wrap it into a OneVsOneClassifier that can be applied to any classifier.\n",
    "\n",
    "(Note that other classifiers natively implement OvO, e.g., sklearn.svm.SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "m7OH-NU6E08_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),  # feature extraction\n",
    "    ('sel', SelectKBest(chi2, k=3000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', OneVsOneClassifier( MLPClassifier(random_state=1, max_iter=300)))  # learning algorithm\n",
    "])\n",
    "\n",
    "classifier = pipeline.fit(x_train,y_train)\n",
    "predictions = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ewi5pJIraQPo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         G06       0.66      0.66      0.66      2845\n",
      "         H04       0.62      0.54      0.58      1622\n",
      "          NA       0.66      0.71      0.68      2067\n",
      "\n",
      "    accuracy                           0.65      6534\n",
      "   macro avg       0.65      0.64      0.64      6534\n",
      "weighted avg       0.65      0.65      0.65      6534\n",
      "\n",
      "Confusion matrix:\n",
      "[[1891  443  511]\n",
      " [ 487  883  252]\n",
      " [ 494  101 1472]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5kQl_2CpfYLK"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomizedSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-eee119bd55ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'n_neighbors'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weights'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'uniform'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'distance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'f1_weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mreport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomizedSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "parameters = {'n_neighbors': np.arange(1, 10 + 1), 'weights':['uniform', 'distance']}\n",
    "\n",
    "search = RandomizedSearchCV(KNeighborsClassifier(), parameters,cv = 10, scoring = 'f1_weighted')\n",
    "search.fit(x_train, y_train)\n",
    "report(search.cv_results_, n_top=3)\n",
    "clf = search.best_estimator_\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TFBertForSequenceClassification' from 'transformers' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-1c536e0a9d53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTFBertForSequenceClassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTFBertModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTFRobertaForSequenceClassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRobertaTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTFDistilBertModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDistilBertTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTFDistilBertForSequenceClassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mElectraTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTFElectraForSequenceClassification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'TFBertForSequenceClassification' from 'transformers' (unknown location)"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, TFBertModel, TFRobertaForSequenceClassification, RobertaTokenizer\n",
    "from transformers import TFDistilBertModel, DistilBertTokenizer, TFDistilBertForSequenceClassification, ElectraTokenizer, TFElectraForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DistilBertTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-f027b3c85c15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDistilBertTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# tokenizer init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DistilBertTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name) # tokenizer init\n",
    "\n",
    "def build_model():\n",
    "    with strategy.scope():\n",
    "        \n",
    "        bert_encoder = TFDistilBertForSequenceClassification.from_pretrained(model_name)\n",
    "  \n",
    "        \n",
    "        # define tensors for inputs\n",
    "        input_word_ids = tf.keras.Input(shape=(None,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "        input_mask = tf.keras.Input(shape=(None,), dtype=tf.int32, name=\"input_mask\")\n",
    "        \n",
    "        # Define model for fine-tuning Bert\n",
    "        \n",
    "        ### Embedding layer extracted from pretrained BERT\n",
    "        embedding = bert_encoder([input_word_ids, input_mask])[0]\n",
    "        \n",
    "        ### Layers for Classification task\n",
    "        output_layer = tf.keras.layers.Dropout(0.2)(embedding)\n",
    "        output_dense_layer = tf.keras.layers.Dense(64, activation='relu')(output_layer)\n",
    "        output_dense_layer = tf.keras.layers.Dropout(0.1)(output_dense_layer)\n",
    "        output_dense_layer = tf.keras.layers.Dense(32, activation='relu')(output_dense_layer)\n",
    "        output = tf.keras.layers.Dense(3, activation='softmax')(output_dense_layer)\n",
    "\n",
    "        # Define Training parameters\n",
    "        ## Optimizer is ADAM\n",
    "        ## Function Loss is CrossEntropy\n",
    "        ## Metric for evaluation is a standard accuracy\n",
    "        model = tf.keras.Model(inputs=[input_word_ids, input_mask], outputs=output)\n",
    "        model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "# Init DeepLearning Model \n",
    "with strategy.scope():\n",
    "    model = build_model()\n",
    "    model.summary() # this describe model architecture and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def make_dataset(train_input, train_label):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            train_input,\n",
    "            train_label\n",
    "        )\n",
    "    ).repeat().shuffle(batch_size).batch(batch_size).prefetch(auto)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def bert_encode(hypotheses, premises, augmentation=False):\n",
    "    num_examples = len(hypotheses)\n",
    "\n",
    "    # sentence_1 = [tokenizer.encode(s) for s in premises]\n",
    "    # sentence_2 = [tokenizer.encode(s) for s in hypotheses]\n",
    "    input_word_ids = [tokenizer.encode(s1,s2) for s1,s2 in zip(premises,hypotheses)  ]\n",
    "    # input_word_ids = list(map(lambda x: x[0]+x[1], list(zip(sentence_1,sentence_2))))\n",
    "    input_mask = [np.ones_like(x) for x in input_word_ids]\n",
    "    inputs = {\n",
    "        'input_word_ids': tf.keras.preprocessing.sequence.pad_sequences(input_word_ids, padding='post', maxlen=MAX_LEN, truncating='post'),\n",
    "        'input_mask': tf.keras.preprocessing.sequence.pad_sequences(input_mask, padding='post', maxlen=MAX_LEN, truncating='post')\n",
    "    }\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['prediction'] = 0\n",
    "num_augmentation = 1\n",
    "\n",
    "# encoding training data\n",
    "train_input = bert_encode(train_df.hypothesis.values,train_df.premise.values, augmentation=False)\n",
    "train_label = train_df.label.values\n",
    "\n",
    "# create data Iterator for training \n",
    "train_sequence = make_dataset(train_input, train_label)\n",
    "\n",
    "# encoding validation data\n",
    "validation_input = bert_encode(val_df.hypothesis.values, val_df.premise.values, augmentation=False)\n",
    "validation_label = val_df.label.values\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = (len(train_label)) // batch_size\n",
    "\n",
    "with strategy.scope():\n",
    "    history = model.fit(\n",
    "        train_sequence, shuffle=True, steps_per_epoch=n_steps, \n",
    "        validation_data = (validation_input, validation_label), epochs=50, verbose=1,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                'model.h5', monitor='val_accuracy', save_best_only=True,save_weights_only=True)\n",
    "        ]\n",
    "    ) \n",
    "\n",
    "# save trained model\n",
    "model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul of validation Accuracy\n",
    "validation_predictions = model.predict(validation_input)\n",
    "validation_predictions = np.argmax(validation_predictions, axis=-1)\n",
    "val_df['predictions'] = validation_predictions\n",
    "acc = accuracy_score(validation_label, validation_predictions)\n",
    "print('Accuracy: {}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "06.1 - Classification - sklearn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
