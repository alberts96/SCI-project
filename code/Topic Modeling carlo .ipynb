{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re \n",
    "import gensim \n",
    "import json\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title        0\n",
      "pub_date     0\n",
      "citations    0\n",
      "abstract     0\n",
      "class        0\n",
      "year         0\n",
      "dtype: int64\n",
      "length is 9476\n"
     ]
    }
   ],
   "source": [
    "ids = pd.read_csv(r\"../data/gp-q2-clean.csv\",index_col='code',skipinitialspace=True)\n",
    "print(ids.isnull().sum())\n",
    "print('length is',len(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>link</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>85062908267</td>\n",
       "      <td>Terrorist network analysis and identification ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>The prediction of terrorist network and identi...</td>\n",
       "      <td>Internet of things; Learning algorithms; Smart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85092037876</td>\n",
       "      <td>Who makes revolution in the age of speculative...</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>Contemporary theories of social emancipation c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85061535070</td>\n",
       "      <td>One-shot learning approach for unknown malware...</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>Early detection of new kinds of malware always...</td>\n",
       "      <td>Character recognition; Classification (of info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85055699089</td>\n",
       "      <td>Regulating Artificial Intelligence Proposal fo...</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>Given the ubiquity of artificial intelligence ...</td>\n",
       "      <td>Autonomous vehicles; International trade; Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85061405847</td>\n",
       "      <td>Defending Against Adversarial Samples Without ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>It has been recently shown that deep neural ne...</td>\n",
       "      <td>Computer crime; Data mining; Deep neural netwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85012264765</td>\n",
       "      <td>Mathematical fortune-telling</td>\n",
       "      <td>2001</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>This is an informal introduction to the physic...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77956055808</td>\n",
       "      <td>Selection of behavior in social situations app...</td>\n",
       "      <td>2001</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>The law of effect is a very simple law which r...</td>\n",
       "      <td>Computer science; Computers; Adaptive behavior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35786351</td>\n",
       "      <td>Compactness measurement using Fuzzy Multicrite...</td>\n",
       "      <td>2001</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>This paper presents a new method for compactne...</td>\n",
       "      <td>Algorithms; Decision making; Decision support ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34259205</td>\n",
       "      <td>From data to insight: the critical path to dat...</td>\n",
       "      <td>2000</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>The data mining methodology is important to de...</td>\n",
       "      <td>Computer software; Graphical user interfaces; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84959208309</td>\n",
       "      <td>Time and message optimal leader election in as...</td>\n",
       "      <td>2000</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>We consider the problem of leader election in ...</td>\n",
       "      <td>Artificial intelligence; Computer science; Com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7981 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         title  year  \\\n",
       "code                                                                   \n",
       "85062908267  Terrorist network analysis and identification ...  2018   \n",
       "85092037876  Who makes revolution in the age of speculative...  2018   \n",
       "85061535070  One-shot learning approach for unknown malware...  2018   \n",
       "85055699089  Regulating Artificial Intelligence Proposal fo...  2018   \n",
       "85061405847  Defending Against Adversarial Samples Without ...  2018   \n",
       "...                                                        ...   ...   \n",
       "85012264765                       Mathematical fortune-telling  2001   \n",
       "77956055808  Selection of behavior in social situations app...  2001   \n",
       "35786351     Compactness measurement using Fuzzy Multicrite...  2001   \n",
       "34259205     From data to insight: the critical path to dat...  2000   \n",
       "84959208309  Time and message optimal leader election in as...  2000   \n",
       "\n",
       "                                                          link  \\\n",
       "code                                                             \n",
       "85062908267  https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "85092037876  https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "85061535070  https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "85055699089  https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "85061405847  https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "...                                                        ...   \n",
       "85012264765  https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "77956055808  https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "35786351     https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "34259205     https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "84959208309  https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "\n",
       "                                                      abstract  \\\n",
       "code                                                             \n",
       "85062908267  The prediction of terrorist network and identi...   \n",
       "85092037876  Contemporary theories of social emancipation c...   \n",
       "85061535070  Early detection of new kinds of malware always...   \n",
       "85055699089  Given the ubiquity of artificial intelligence ...   \n",
       "85061405847  It has been recently shown that deep neural ne...   \n",
       "...                                                        ...   \n",
       "85012264765  This is an informal introduction to the physic...   \n",
       "77956055808  The law of effect is a very simple law which r...   \n",
       "35786351     This paper presents a new method for compactne...   \n",
       "34259205     The data mining methodology is important to de...   \n",
       "84959208309  We consider the problem of leader election in ...   \n",
       "\n",
       "                                                       keyword  \n",
       "code                                                            \n",
       "85062908267  Internet of things; Learning algorithms; Smart...  \n",
       "85092037876                                                NaN  \n",
       "85061535070  Character recognition; Classification (of info...  \n",
       "85055699089  Autonomous vehicles; International trade; Pers...  \n",
       "85061405847  Computer crime; Data mining; Deep neural netwo...  \n",
       "...                                                        ...  \n",
       "85012264765                                                NaN  \n",
       "77956055808  Computer science; Computers; Adaptive behavior...  \n",
       "35786351     Algorithms; Decision making; Decision support ...  \n",
       "34259205     Computer software; Graphical user interfaces; ...  \n",
       "84959208309  Artificial intelligence; Computer science; Com...  \n",
       "\n",
       "[7981 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arts = pd.read_csv(r\"../data/scopus-q2-clean.csv\",index_col='code',skipinitialspace=True)\n",
    "arts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9476 7981\n"
     ]
    }
   ],
   "source": [
    "x_train = [abstract for abstract in ids.abstract]\n",
    "x_test = [abstract for abstract in arts.abstract]\n",
    "\n",
    "print(len(x_train),len(x_test))\n",
    "#x_train = x_train.extend(x_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\carlo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "it_stopwords = stopwords.words('english')\n",
    "\n",
    "tf_vectorizer = CountVectorizer(stop_words=it_stopwords, max_df=0.5, min_df=5,max_features = 1000, ngram_range=(1,2))\n",
    "tf = tf_vectorizer.fit_transform(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 10\n",
      "iteration: 2 of max_iter: 10\n",
      "iteration: 3 of max_iter: 10\n",
      "iteration: 4 of max_iter: 10\n",
      "iteration: 5 of max_iter: 10\n",
      "iteration: 6 of max_iter: 10\n",
      "iteration: 7 of max_iter: 10\n",
      "iteration: 8 of max_iter: 10\n",
      "iteration: 9 of max_iter: 10\n",
      "iteration: 10 of max_iter: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=8, n_jobs=-1,\n",
       "                          perp_tol=0.1, random_state=None,\n",
       "                          topic_word_prior=None, total_samples=1000000.0,\n",
       "                          verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "n_components = 8\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=10,\n",
    "                                learning_method = 'batch',\n",
    "                                n_jobs=-1,verbose=1)\n",
    "lda.fit(tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = f'Topic {topic_idx}: '\n",
    "        message += ', '.join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: system, information, module, control, unit, invention, data, terminal, present, communication, vehicle, present invention, mobile, monitoring, method, image, management, signal, processing, server\n",
      "Topic 1: user, device, authentication, information, service, client, server, access, request, mobile, devices, application, system, based, method, may, computing, electronic, users, response\n",
      "Topic 2: one, least, first, least one, based, plurality, event, system, set, associated, second, method, includes, may, security, events, score, entity, data, determining\n",
      "Topic 3: data, content, system, may, message, search, processing, query, key, based, one, method, storage, document, time, includes, set, using, first, encrypted\n",
      "Topic 4: information, system, security, network, object, web, image, risk, domain, video, computer, based, systems, internet, objects, threat, management, database, method, website\n",
      "Topic 5: computer, file, may, computing, application, include, disclosed, systems, methods, method, may include, implemented, security, system, computer implemented, media, also, readable, implemented method, identifying\n",
      "Topic 6: method, model, detection, malicious, feature, invention, learning, data, based, training, using, software, network, behavior, classification, machine, code, target, according, machine learning\n",
      "Topic 7: network, device, first, traffic, second, node, one, transaction, based, communication, processor, electronic, nodes, includes, configured, data, plurality, digital, block, network traffic\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 20\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: system, information, module, control, unit, invention, data, terminal, present, communication, vehicle, present invention, mobile, monitoring, method, image, management, signal, processing, server\n",
      "Topic 1: user, device, authentication, information, service, client, server, access, request, mobile, devices, application, system, based, method, may, computing, electronic, users, response\n",
      "Topic 2: one, least, first, least one, based, plurality, event, system, set, associated, second, method, includes, may, security, events, score, entity, data, determining\n",
      "Topic 3: data, content, system, may, message, search, processing, query, key, based, one, method, storage, document, time, includes, set, using, first, encrypted\n",
      "Topic 4: information, system, security, network, object, web, image, risk, domain, video, computer, based, systems, internet, objects, threat, management, database, method, website\n",
      "Topic 5: computer, file, may, computing, application, include, disclosed, systems, methods, method, may include, implemented, security, system, computer implemented, media, also, readable, implemented method, identifying\n",
      "Topic 6: method, model, detection, malicious, feature, invention, learning, data, based, training, using, software, network, behavior, classification, machine, code, target, according, machine learning\n",
      "Topic 7: network, device, first, traffic, second, node, one, transaction, based, communication, processor, electronic, nodes, includes, configured, data, plurality, digital, block, network traffic\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 20\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14409507, 0.55646959, 0.0487804 , ..., 0.00140566, 0.00141114,\n",
       "        0.10314256],\n",
       "       [0.00131722, 0.09726356, 0.07766972, ..., 0.00131836, 0.14949885,\n",
       "        0.47326471],\n",
       "       [0.00278073, 0.13884967, 0.00278316, ..., 0.00278573, 0.00278094,\n",
       "        0.6064935 ],\n",
       "       ...,\n",
       "       [0.46225237, 0.00173752, 0.37231395, ..., 0.12003534, 0.00173891,\n",
       "        0.0384441 ],\n",
       "       [0.00255488, 0.00255604, 0.84535513, ..., 0.00255329, 0.13931576,\n",
       "        0.00255299],\n",
       "       [0.00338548, 0.18879345, 0.33897108, ..., 0.00338034, 0.45532425,\n",
       "        0.003383  ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topics = lda.transform(tf)\n",
    "doc_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1586\n",
       "6    1475\n",
       "0    1435\n",
       "1    1125\n",
       "5    1046\n",
       "3    1026\n",
       "4     974\n",
       "7     809\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topics = lda.transform(tf)\n",
    "ids['topic'] = np.argmax(doc_topics,axis=1)\n",
    "ids['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1586 4628\n",
      "1475 2101\n",
      "1435 472\n",
      "1125 298\n",
      "1046 217\n",
      "1026 131\n",
      "974 97\n",
      "809 37\n"
     ]
    }
   ],
   "source": [
    "for a,b in zip(ids['topic'].value_counts(),arts['topic'].value_counts()): print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1586 217\n",
      "6 1475 4628\n",
      "0 1435 298\n",
      "1 1125 131\n",
      "5 1046 37\n",
      "3 1026 472\n",
      "4 974 2101\n",
      "7 809 97\n"
     ]
    }
   ],
   "source": [
    "for i in ids['topic'].value_counts().keys(): print(i,ids['topic'].value_counts()[i],arts['topic'].value_counts()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf2 = tf_vectorizer.transform(x_test)\n",
    "arts_topics = lda.transform(tf2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    4628\n",
       "4    2101\n",
       "3     472\n",
       "0     298\n",
       "2     217\n",
       "1     131\n",
       "7      97\n",
       "5      37\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arts['topic'] = np.argmax(arts_topics,axis=1)\n",
    "arts['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.to_csv('../data/gp-q2-topics.csv')\n",
    "arts.to_csv('../data/scopus-q2-topics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOCS\n",
    "here we use directy patet + papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>doctype</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>85062908267</td>\n",
       "      <td>Terrorist network analysis and identification ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>the prediction of terrorist network and identi...</td>\n",
       "      <td>paper</td>\n",
       "      <td>NAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85092037876</td>\n",
       "      <td>Who makes revolution in the age of speculative...</td>\n",
       "      <td>2018</td>\n",
       "      <td>contemporary theories of social emancipation c...</td>\n",
       "      <td>paper</td>\n",
       "      <td>NAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85061535070</td>\n",
       "      <td>One-shot learning approach for unknown malware...</td>\n",
       "      <td>2018</td>\n",
       "      <td>early detection of new kinds of malware always...</td>\n",
       "      <td>paper</td>\n",
       "      <td>NAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85055699089</td>\n",
       "      <td>Regulating Artificial Intelligence Proposal fo...</td>\n",
       "      <td>2018</td>\n",
       "      <td>given the ubiquity of artificial intelligence ...</td>\n",
       "      <td>paper</td>\n",
       "      <td>NAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85061405847</td>\n",
       "      <td>Defending Against Adversarial Samples Without ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>it has been recently shown that deep neural ne...</td>\n",
       "      <td>paper</td>\n",
       "      <td>NAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         title  year  \\\n",
       "code                                                                   \n",
       "85062908267  Terrorist network analysis and identification ...  2018   \n",
       "85092037876  Who makes revolution in the age of speculative...  2018   \n",
       "85061535070  One-shot learning approach for unknown malware...  2018   \n",
       "85055699089  Regulating Artificial Intelligence Proposal fo...  2018   \n",
       "85061405847  Defending Against Adversarial Samples Without ...  2018   \n",
       "\n",
       "                                                      abstract doctype class  \n",
       "code                                                                          \n",
       "85062908267  the prediction of terrorist network and identi...   paper   NAN  \n",
       "85092037876  contemporary theories of social emancipation c...   paper   NAN  \n",
       "85061535070  early detection of new kinds of malware always...   paper   NAN  \n",
       "85055699089  given the ubiquity of artificial intelligence ...   paper   NAN  \n",
       "85061405847  it has been recently shown that deep neural ne...   paper   NAN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = pd.read_csv('../data/docs-clean.csv', index_col='code')\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = docs\n",
    "ids = ids[ids.abstract.notna()]\n",
    "x_train = [abstract for abstract in ids.abstract]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\carlo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "it_stopwords = stopwords.words('english')\n",
    "\n",
    "tf_vectorizer = CountVectorizer(stop_words=it_stopwords, max_df=0.5, min_df=5,max_features = 1000, ngram_range=(1,2))\n",
    "tf = tf_vectorizer.fit_transform(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 10\n",
      "iteration: 2 of max_iter: 10\n",
      "iteration: 3 of max_iter: 10\n",
      "iteration: 4 of max_iter: 10\n",
      "iteration: 5 of max_iter: 10\n",
      "iteration: 6 of max_iter: 10\n",
      "iteration: 7 of max_iter: 10\n",
      "iteration: 8 of max_iter: 10\n",
      "iteration: 9 of max_iter: 10\n",
      "iteration: 10 of max_iter: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=8, n_jobs=-1,\n",
       "                          perp_tol=0.1, random_state=None,\n",
       "                          topic_word_prior=None, total_samples=1000000.0,\n",
       "                          verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "n_components = 8\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=10,\n",
    "                                learning_method = 'batch',\n",
    "                                n_jobs=-1,verbose=1)\n",
    "lda.fit(tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: security, cyber, systems, intelligence, malicious, software, code, attack, attacks, system, domain, artificial, threat, threats, new, artificial intelligence, virtual, paper, also, internet\n",
      "Topic 1: news, network, detection, fake, based, fake news, networks, information, using, learning, paper, real, proposed, approach, model, traffic, research, system, algorithm, results\n",
      "Topic 2: malware, model, based, network, classification, neural, detection, using, learning, deep, analysis, method, training, neural network, feature, iot, features, deep learning, data, image\n",
      "Topic 3: data, device, one, network, first, may, least, based, system, second, associated, user, least one, plurality, computing, includes, devices, content, traffic, communication\n",
      "Topic 4: user, information, system, data, service, module, method, authentication, server, invention, control, access, device, management, based, terminal, unit, present, vehicle, message\n",
      "Topic 5: malware, detection, learning, machine, machine learning, based, android, features, malicious, malware detection, paper, using, accuracy, proposed, detect, applications, used, techniques, system, results\n",
      "Topic 6: data, social, media, analysis, social media, information, content, big, big data, twitter, users, political, text, using, used, election, based, results, online, use\n",
      "Topic 7: method, data, file, computer, system, image, invention, based, set, information, application, target, determining, one, disclosed, event, include, identifying, object, according\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 20\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    3590\n",
       "5    2947\n",
       "4    2450\n",
       "7    2258\n",
       "1    1976\n",
       "6    1749\n",
       "0    1468\n",
       "2    1019\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topics = lda.transform(tf)\n",
    "ids['topic'] = np.argmax(doc_topics,axis=1)\n",
    "ids.topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>topic</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctype</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>paper</td>\n",
       "      <td>1143</td>\n",
       "      <td>1906</td>\n",
       "      <td>591</td>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>2800</td>\n",
       "      <td>1454</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>patent</td>\n",
       "      <td>325</td>\n",
       "      <td>70</td>\n",
       "      <td>428</td>\n",
       "      <td>3586</td>\n",
       "      <td>2378</td>\n",
       "      <td>147</td>\n",
       "      <td>295</td>\n",
       "      <td>2247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "topic       0     1    2     3     4     5     6     7\n",
       "doctype                                               \n",
       "paper    1143  1906  591     4    72  2800  1454    11\n",
       "patent    325    70  428  3586  2378   147   295  2247"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(ids['doctype'],ids['topic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEnsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gensim\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = English()\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>doctype</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>85062908267</td>\n",
       "      <td>Terrorist network analysis and identification ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>the prediction of terrorist network and identi...</td>\n",
       "      <td>paper</td>\n",
       "      <td>NAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85092037876</td>\n",
       "      <td>Who makes revolution in the age of speculative...</td>\n",
       "      <td>2018</td>\n",
       "      <td>contemporary theories of social emancipation c...</td>\n",
       "      <td>paper</td>\n",
       "      <td>NAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85061535070</td>\n",
       "      <td>One-shot learning approach for unknown malware...</td>\n",
       "      <td>2018</td>\n",
       "      <td>early detection of new kinds of malware always...</td>\n",
       "      <td>paper</td>\n",
       "      <td>NAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85055699089</td>\n",
       "      <td>Regulating Artificial Intelligence Proposal fo...</td>\n",
       "      <td>2018</td>\n",
       "      <td>given the ubiquity of artificial intelligence ...</td>\n",
       "      <td>paper</td>\n",
       "      <td>NAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85061405847</td>\n",
       "      <td>Defending Against Adversarial Samples Without ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>it has been recently shown that deep neural ne...</td>\n",
       "      <td>paper</td>\n",
       "      <td>NAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         title  year  \\\n",
       "code                                                                   \n",
       "85062908267  Terrorist network analysis and identification ...  2018   \n",
       "85092037876  Who makes revolution in the age of speculative...  2018   \n",
       "85061535070  One-shot learning approach for unknown malware...  2018   \n",
       "85055699089  Regulating Artificial Intelligence Proposal fo...  2018   \n",
       "85061405847  Defending Against Adversarial Samples Without ...  2018   \n",
       "\n",
       "                                                      abstract doctype class  \n",
       "code                                                                          \n",
       "85062908267  the prediction of terrorist network and identi...   paper   NAN  \n",
       "85092037876  contemporary theories of social emancipation c...   paper   NAN  \n",
       "85061535070  early detection of new kinds of malware always...   paper   NAN  \n",
       "85055699089  given the ubiquity of artificial intelligence ...   paper   NAN  \n",
       "85061405847  it has been recently shown that deep neural ne...   paper   NAN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = pd.read_csv('../data/docs-clean.csv', index_col='code')\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = docs['abstract'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "texts = [[w for w in text.split(' ') if w not in stopwords] for text in x_train] #tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "tfidf = models.TfidfModel(corpus) \n",
    "\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=8, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [scores[np.argmax([score[1] for score in scores])][0] for scores in lda_model.get_document_topics(corpus) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC  0 :  [(656, 0.07298501), (3511, 0.06786042), (1641, 0.026658064), (923, 0.023507943), (805, 0.019785155), (767, 0.019587766), (648, 0.018938249), (2408, 0.01839882), (1645, 0.017397333), (546, 0.015544288)]\n",
      "TOPIC  1 :  [(1901, 0.108384036), (1865, 0.097540714), (21782, 0.091617346), (7699, 0.067549355), (400, 0.031842597), (41626, 0.020621914), (6791, 0.020197736), (41572, 0.016224992), (4109, 0.015916632), (4978, 0.0121265035)]\n",
      "TOPIC  2 :  [(322, 0.035775743), (886, 0.025024831), (460, 0.023265406), (4402, 0.019195244), (1166, 0.016796492), (1761, 0.015895726), (842, 0.01578771), (3971, 0.012511091), (4806, 0.011436595), (1080, 0.011002939)]\n",
      "TOPIC  3 :  [(282, 0.04785681), (38, 0.029460937), (169, 0.026424186), (0, 0.024500204), (24, 0.017419834), (35, 0.0160064), (439, 0.013133688), (1562, 0.009949418), (7, 0.008941776), (964, 0.0083625)]\n",
      "TOPIC  4 :  [(6276, 0.07324232), (4853, 0.03355926), (1187, 0.02791631), (4015, 0.023547702), (879, 0.01818989), (42824, 0.015513118), (3750, 0.014419505), (8597, 0.013759376), (3294, 0.012596824), (7888, 0.011953779)]\n",
      "TOPIC  5 :  [(1216, 0.10439832), (426, 0.081875734), (26, 0.076188326), (571, 0.029041346), (1683, 0.0284924), (375, 0.024747057), (1440, 0.01909839), (877, 0.018647173), (543, 0.018535208), (3910, 0.017717123)]\n",
      "TOPIC  6 :  [(155, 0.024695821), (24, 0.024456326), (320, 0.021949489), (1278, 0.020665113), (461, 0.017233841), (480, 0.013612726), (491, 0.01355439), (972, 0.011932418), (905, 0.011590807), (455, 0.011199449)]\n",
      "TOPIC  7 :  [(3798, 0.09662401), (4985, 0.05709744), (4439, 0.04788373), (998, 0.043312773), (401, 0.025541542), (4518, 0.021961818), (1436, 0.021248182), (3794, 0.019517494), (3744, 0.018240305), (6963, 0.01643549)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(8): \n",
    "    print('TOPIC ',i,': ', lda_model.get_topic_terms(i, topn=10))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.073*\"content\" + 0.068*\"receiving\" + 0.027*\"flow\" + 0.024*\"domain\" + 0.020*\"graph\" + 0.020*\"search\" + 0.019*\"web\" + 0.018*\"obtaining\" + 0.017*\"list\" + 0.016*\"document\"'),\n",
       " (1,\n",
       "  '0.108*\")\" + 0.098*\"(\" + 0.092*\"invention\" + 0.068*\"plurality\" + 0.032*\"media\" + 0.021*\"computer-readable\" + 0.020*\"apparatus\" + 0.016*\"computer-implemented\" + 0.016*\"query\" + 0.012*\"said\"'),\n",
       " (2,\n",
       "  '0.036*\"module\" + 0.025*\"control\" + 0.023*\"image\" + 0.019*\"vehicle\" + 0.017*\"object\" + 0.016*\"video\" + 0.016*\"signal\" + 0.013*\"wireless\" + 0.011*\"sensor\" + 0.011*\"monitoring\"'),\n",
       " (3,\n",
       "  '0.048*\"data\" + 0.029*\"system\" + 0.026*\"information\" + 0.025*\"\" + 0.017*\"method\" + 0.016*\"security\" + 0.013*\"based\" + 0.010*\"second\" + 0.009*\"computing\" + 0.008*\"includes\"'),\n",
       " (4,\n",
       "  '0.073*\"electronic\" + 0.034*\"storing\" + 0.028*\"id\" + 0.024*\"included\" + 0.018*\"assets\" + 0.016*\"der\" + 0.014*\"entry\" + 0.014*\"responsive\" + 0.013*\"des\" + 0.012*\"un\"'),\n",
       " (5,\n",
       "  '0.104*\"device\" + 0.082*\"user\" + 0.076*\"network\" + 0.029*\"server\" + 0.028*\"service\" + 0.025*\"communication\" + 0.019*\"client\" + 0.019*\"access\" + 0.019*\"devices\" + 0.018*\"configured\"'),\n",
       " (6,\n",
       "  '0.025*\"detection\" + 0.024*\"method\" + 0.022*\"model\" + 0.021*\"file\" + 0.017*\"malicious\" + 0.014*\"software\" + 0.014*\"code\" + 0.012*\"program\" + 0.012*\"set\" + 0.011*\"feature\"'),\n",
       " (7,\n",
       "  '0.097*\"message\" + 0.057*\"display\" + 0.048*\"block\" + 0.043*\"medium\" + 0.026*\"messages\" + 0.022*\"voice\" + 0.021*\"card\" + 0.020*\"instance\" + 0.018*\"multimedia\" + 0.016*\"setting\"')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics(num_topics=8, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    11151\n",
       "6     5445\n",
       "5      277\n",
       "1      274\n",
       "2      211\n",
       "0       55\n",
       "4       40\n",
       "7        4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(topics).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patents = pd.read_csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
